<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fluid Expression System - Big Hero 6 Style Avatar (High Quality)</title>
    
    <!-- Core Libraries (no SocketIO) -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/gsap.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/flubber@0.4.2/build/flubber.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/sentiment@5.0.2/build/sentiment.min.js"></script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .demo-container {
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            max-width: 800px;
            width: 100%;
        }

        .title {
            text-align: center;
            color: #2c3e50;
            margin-bottom: 30px;
            font-size: 2.5em;
            font-weight: 300;
        }

        .subtitle {
            text-align: center;
            color: #7f8c8d;
            margin-bottom: 40px;
            font-size: 1.1em;
        }

        .avatar-container {
            display: flex;
            justify-content: center;
            margin-bottom: 40px;
            width: 100%; /* Full width container */
            max-width: 800px; /* Match demo container max-width */
        }

        #avatarContainer {
            width: 400px;
            height: 300px;
            min-width: 400px;  /* Prevent shrinking */
            max-width: 400px;  /* Prevent growing */
            min-height: 300px; /* Prevent shrinking */
            max-height: 300px; /* Prevent growing */
            border-radius: 20px;
            background: linear-gradient(145deg, #f0f0f0, #e6e6e6);
            border: 3px solid #e9ecef;
            overflow: hidden;
            position: relative;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 
                inset 0 2px 4px rgba(255,255,255,0.8),
                inset 0 -2px 4px rgba(0,0,0,0.1),
                0 8px 16px rgba(0,0,0,0.1);
            flex-shrink: 0; /* Prevent flexbox from shrinking this */
        }

        .avatar-face {
            width: 400px;    /* Fixed width */
            height: 300px;   /* Fixed height */
            max-width: 100%;
            max-height: 100%;
            filter: drop-shadow(0 2px 4px rgba(0,0,0,0.1));
        }

        .controls {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
            gap: 15px;
            margin-bottom: 30px;
        }

        .control-button {
            padding: 12px 20px;
            border: none;
            border-radius: 10px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .emotion-btn {
            background: #3498db;
            color: white;
        }

        .emotion-btn:hover {
            background: #2980b9;
            transform: translateY(-2px);
        }

        .emotion-btn.active {
            background: #e74c3c;
            box-shadow: 0 5px 15px rgba(231, 76, 60, 0.3);
        }

        .settings-section {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .settings-title {
            font-size: 1.2em;
            color: #2c3e50;
            margin-bottom: 15px;
            font-weight: 600;
        }

        .setting-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
            padding: 8px 0;
            border-bottom: 1px solid #e9ecef;
        }

        .setting-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
        }

        .toggle {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 25px;
        }

        .toggle input {
            opacity: 0;
            width: 0;
            height: 0;
        }

        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 25px;
        }

        .slider:before {
            position: absolute;
            content: "";
            height: 19px;
            width: 19px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }

        input:checked + .slider {
            background-color: #3498db;
        }

        input:checked + .slider:before {
            transform: translateX(25px);
        }

        .text-input-section {
            margin-bottom: 20px;
        }

        .text-input {
            width: 100%;
            padding: 15px;
            border: 2px solid #e9ecef;
            border-radius: 10px;
            font-size: 16px;
            margin-bottom: 10px;
            transition: border-color 0.3s ease;
        }

        .text-input:focus {
            outline: none;
            border-color: #3498db;
        }

        .analyze-btn {
            background: #27ae60;
            color: white;
            padding: 12px 25px;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            margin-right: 10px;
            margin-bottom: 10px;
            transition: background 0.3s ease;
        }

        .analyze-btn:hover {
            background: #229954;
        }

        .demo-text-samples {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 10px;
        }

        .sample-btn {
            background: #f39c12;
            color: white;
            padding: 8px 15px;
            border: none;
            border-radius: 6px;
            font-size: 12px;
            cursor: pointer;
            transition: background 0.3s ease;
        }

        .sample-btn:hover {
            background: #e67e22;
        }

        .performance-metrics {
            background: #2c3e50;
            color: white;
            padding: 15px;
            border-radius: 10px;
            margin-top: 20px;
        }

        .metric-row {
            display: flex;
            justify-content: space-between;
            padding: 5px 0;
            border-bottom: 1px solid #34495e;
        }

        .metric-row:last-child {
            border-bottom: none;
        }

        .status-indicator {
            text-align: center;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            background: #27ae60;
            color: white;
            font-weight: 600;
            height: 140px;
            box-sizing: border-box;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        .api-status {
            font-size: 12px;
            opacity: 0.8;
            margin-top: 5px;
        }

        .quality-indicator {
            text-align: center;
            padding: 8px;
            margin-bottom: 15px;
            border-radius: 6px;
            background: #3498db;
            color: white;
            font-size: 12px;
            font-weight: 600;
        }
    </style>
</head>
<body>
    <div class="demo-container">
        <h1 class="title">üé≠ Big Hero 6 Expression System</h1>
        <p class="subtitle">High-Quality Fluid Avatar Expressions with Real-time Sentiment Analysis</p>
        
        <div class="status-indicator" id="statusIndicator">
            <div>‚úÖ System Running in High Quality Mode</div>
            <div class="api-status" id="apiStatus">Connecting to server...</div>
            <div class="api-status" id="audioStatus" style="display: none;">üé§ Real-time Audio Lip Sync Active</div>
        </div>
        
        <div class="quality-indicator">
            üé® High Resolution SVG ‚Ä¢ Smooth Morphing ‚Ä¢ Enhanced Gradients ‚Ä¢ 60fps Target
        </div>
        
        <div class="avatar-container">
            <div id="avatarContainer"></div>
        </div>
        
        <div class="controls">
            <button class="control-button emotion-btn" onclick="setEmotion('neutral')">üòê Neutral</button>
            <button class="control-button emotion-btn active" onclick="setEmotion('idle')">üòå Idle</button>
            <button class="control-button emotion-btn" onclick="setEmotion('happy')">üòä Happy</button>
            <button class="control-button emotion-btn" onclick="setEmotion('sad')">üò¢ Sad</button>
            <button class="control-button emotion-btn" onclick="setEmotion('surprised')">üò≤ Surprised</button>
            <button class="control-button emotion-btn" onclick="setEmotion('thinking')">ü§î Thinking</button>
            <button class="control-button emotion-btn" onclick="setEmotion('speaking')">üó£Ô∏è Speaking</button>
            <button class="control-button emotion-btn" onclick="setEmotion('confused')">üòï Confused</button>
            <button class="control-button emotion-btn" onclick="setEmotion('determined')">üò§ Determined</button>
            <button class="control-button emotion-btn" onclick="setEmotion('concerned')">üòü Concerned</button>
            <button class="control-button emotion-btn" onclick="setEmotion('amazed')">ü§© Amazed</button>
            <button class="control-button emotion-btn" onclick="setEmotion('skeptical')">ü§® Skeptical</button>
            <button class="control-button emotion-btn" onclick="setEmotion('ecstatic')">ü•≥ Ecstatic</button>
            <button class="control-button emotion-btn" onclick="testSVGMouth()">üß™ Test Parametric Mouth</button>
        </div>
        
        <div class="settings-section">
            <h3 class="settings-title">‚öôÔ∏è System Settings</h3>
            <div class="setting-item">
                <span>Real-time Sentiment Analysis</span>
                <label class="toggle">
                    <input type="checkbox" id="sentimentToggle" checked>
                    <span class="slider"></span>
                </label>
            </div>
            <div class="setting-item">
                <span>Performance Monitoring</span>
                <label class="toggle">
                    <input type="checkbox" id="performanceToggle">
                    <span class="slider"></span>
                </label>
            </div>
            <div class="setting-item">
                <span>High Quality Rendering</span>
                <label class="toggle">
                    <input type="checkbox" id="qualityToggle" checked>
                    <span class="slider"></span>
                </label>
            </div>
            <div class="setting-item">
                <span>üé§ Real-time Audio Lip Sync</span>
                <label class="toggle">
                    <input type="checkbox" id="audioLipSyncToggle">
                    <span class="slider"></span>
                </label>
            </div>
            <div class="setting-item">
                <span>üó£Ô∏è Speech-to-Text Mode (Enhanced Accuracy)</span>
                <label class="toggle">
                    <input type="checkbox" id="speechRecognitionToggle">
                    <span class="slider"></span>
                </label>
            </div>
        </div>
        
        <div class="text-input-section">
            <input type="text" class="text-input" id="textInput" 
                   placeholder="Enter text to analyze sentiment and trigger expressions...">
            <button class="analyze-btn" onclick="analyzeText()">Analyze Sentiment</button>
            <button class="analyze-btn" onclick="fetchServerSentiment()">Send to Server</button>
            
            <div class="demo-text-samples">
                <button class="sample-btn" onclick="analyzePresetText('I am so excited about this new feature!')">üòä Happy Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('This is really disappointing and frustrating.')">üò¢ Sad Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('Wow, I never expected that to happen!')">üò≤ Surprised Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('Let me think about this carefully...')">ü§î Thinking Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('I am confused about what you mean.')">üòï Confused Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('I am determined to make this work!')">üò§ Determined Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('I am worried this might not work out.')">üòü Concerned Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('This is absolutely incredible and fantastic!')">ü§© Amazed Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('Hmm, I doubt that is really true.')">ü§® Skeptical Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('This is the most amazing thing ever!')">ü•≥ Ecstatic Sample</button>
            </div>
        </div>
        
        <div class="performance-metrics" id="performanceMetrics" style="display: none;">
            <div class="metric-row">
                <span>FPS:</span>
                <span id="fpsMetric">--</span>
            </div>
            <div class="metric-row">
                <span>Current Emotion:</span>
                <span id="emotionMetric">neutral</span>
            </div>
            <div class="metric-row">
                <span>Queue Length:</span>
                <span id="queueMetric">0</span>
            </div>
            <div class="metric-row">
                <span>Animation Frames:</span>
                <span id="framesMetric">0</span>
            </div>
            <div class="metric-row">
                <span>Render Quality:</span>
                <span id="qualityMetric">High</span>
            </div>
        </div>
    </div>

    <script>
        // High Quality Expression System (Enhanced Version)
        class HighQualityExpressionSystem {
            constructor(containerId, options = {}) {
                this.container = document.getElementById(containerId);
                this.options = {
                    enableSentimentAnalysis: true,
                    animationDuration: 200,
                    highQuality: true,
                    ...options
                };
                
                this.currentEmotion = 'idle';
                this.isAnimating = false;
                
                this.init();
            }

            init() {
                this.createHighQualitySVGStructure();
                this.setupEnhancedExpressionPaths();
                this.initializeAnimationSystem();
                this.setupPerformanceMonitoring();
                this.checkServerStatus();
            }

            createHighQualitySVGStructure() {
                // Create high-resolution SVG based on original h1ro.svg design
                this.svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');
                this.svg.setAttribute('viewBox', '0 0 400 300'); // Adjusted for h1ro proportions
                this.svg.setAttribute('width', '400');
                this.svg.setAttribute('height', '300');
                this.svg.setAttribute('preserveAspectRatio', 'xMidYMid meet');
                this.svg.classList.add('avatar-face');
                this.svg.style.shapeRendering = 'geometricPrecision';
                this.svg.style.textRendering = 'optimizeLegibility';
                this.svg.style.overflow = 'visible';
                this.svg.style.display = 'block';
                
                // Create definitions for gradients and filters
                this.createSVGDefinitions();
                
                this.faceGroup = document.createElementNS('http://www.w3.org/2000/svg', 'g');
                this.faceGroup.classList.add('face-group');
                this.faceGroup.style.transformOrigin = '200px 150px'; // Center of 400x300 viewBox
                
                // Head with h1ro styling (oval shape)
                this.head = document.createElementNS('http://www.w3.org/2000/svg', 'path');
                this.head.setAttribute('fill', '#D9D9D9');
                this.head.setAttribute('stroke', '#bbb');
                this.head.setAttribute('stroke-width', '1');
                this.head.setAttribute('filter', 'url(#headGlow)');
                this.head.style.transformOrigin = '200px 120px'; // Center of head shape
                
                // Eyes with h1ro styling (perfect circles)
                this.leftEye = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
                this.leftEye.setAttribute('fill', '#000000');
                this.leftEye.setAttribute('filter', 'url(#eyeShadow)');
                this.leftEye.style.transformOrigin = '105px 120px'; // Center of left eye
                
                this.rightEye = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
                this.rightEye.setAttribute('fill', '#000000');
                this.rightEye.setAttribute('filter', 'url(#eyeShadow)');
                this.rightEye.style.transformOrigin = '295px 120px'; // Center of right eye
                
                // Mouth (replaces bridge) - oval shape like original h1ro
                this.mouth = document.createElementNS('http://www.w3.org/2000/svg', 'ellipse');
                this.mouth.setAttribute('fill', '#000000');
                this.mouth.setAttribute('filter', 'url(#mouthGlow)');
                this.mouth.style.transformOrigin = '200px 180px'; // Center of mouth area
                
                // Assemble SVG
                this.faceGroup.appendChild(this.head);
                this.faceGroup.appendChild(this.leftEye);
                this.faceGroup.appendChild(this.rightEye);
                this.faceGroup.appendChild(this.mouth);
                this.svg.appendChild(this.faceGroup);
                this.container.appendChild(this.svg);
            }

            createSVGDefinitions() {
                const defs = document.createElementNS('http://www.w3.org/2000/svg', 'defs');
                
                // Face gradient
                const faceGradient = document.createElementNS('http://www.w3.org/2000/svg', 'radialGradient');
                faceGradient.setAttribute('id', 'faceGradient');
                faceGradient.setAttribute('cx', '50%');
                faceGradient.setAttribute('cy', '40%');
                faceGradient.setAttribute('r', '60%');
                
                const stop1 = document.createElementNS('http://www.w3.org/2000/svg', 'stop');
                stop1.setAttribute('offset', '0%');
                stop1.setAttribute('stop-color', '#ffffff');
                stop1.setAttribute('stop-opacity', '0.9');
                
                const stop2 = document.createElementNS('http://www.w3.org/2000/svg', 'stop');
                stop2.setAttribute('offset', '100%');
                stop2.setAttribute('stop-color', '#ecf0f1');
                stop2.setAttribute('stop-opacity', '1');
                
                faceGradient.appendChild(stop1);
                faceGradient.appendChild(stop2);
                
                // Drop shadow filter
                const dropShadow = document.createElementNS('http://www.w3.org/2000/svg', 'filter');
                dropShadow.setAttribute('id', 'dropShadow');
                dropShadow.setAttribute('x', '-50%');
                dropShadow.setAttribute('y', '-50%');
                dropShadow.setAttribute('width', '200%');
                dropShadow.setAttribute('height', '200%');
                
                const shadow = document.createElementNS('http://www.w3.org/2000/svg', 'feDropShadow');
                shadow.setAttribute('dx', '0');
                shadow.setAttribute('dy', '2');
                shadow.setAttribute('stdDeviation', '2');
                shadow.setAttribute('flood-color', '#000000');
                shadow.setAttribute('flood-opacity', '0.2');
                
                dropShadow.appendChild(shadow);
                
                // Eye shadow filter
                const eyeShadow = document.createElementNS('http://www.w3.org/2000/svg', 'filter');
                eyeShadow.setAttribute('id', 'eyeShadow');
                
                const eyeShadowEffect = document.createElementNS('http://www.w3.org/2000/svg', 'feDropShadow');
                eyeShadowEffect.setAttribute('dx', '0');
                eyeShadowEffect.setAttribute('dy', '1');
                eyeShadowEffect.setAttribute('stdDeviation', '1');
                eyeShadowEffect.setAttribute('flood-color', '#000000');
                eyeShadowEffect.setAttribute('flood-opacity', '0.3');
                
                eyeShadow.appendChild(eyeShadowEffect);
                
                // Mouth glow filter
                const mouthGlow = document.createElementNS('http://www.w3.org/2000/svg', 'filter');
                mouthGlow.setAttribute('id', 'mouthGlow');
                
                const glow = document.createElementNS('http://www.w3.org/2000/svg', 'feGaussianBlur');
                glow.setAttribute('stdDeviation', '1');
                glow.setAttribute('result', 'coloredBlur');
                
                const merge = document.createElementNS('http://www.w3.org/2000/svg', 'feMerge');
                const mergeNode1 = document.createElementNS('http://www.w3.org/2000/svg', 'feMergeNode');
                mergeNode1.setAttribute('in', 'coloredBlur');
                const mergeNode2 = document.createElementNS('http://www.w3.org/2000/svg', 'feMergeNode');
                mergeNode2.setAttribute('in', 'SourceGraphic');
                
                merge.appendChild(mergeNode1);
                merge.appendChild(mergeNode2);
                mouthGlow.appendChild(glow);
                mouthGlow.appendChild(merge);
                
                defs.appendChild(faceGradient);
                defs.appendChild(dropShadow);
                defs.appendChild(eyeShadow);
                defs.appendChild(mouthGlow);
                this.svg.appendChild(defs);
            }

            setupEnhancedExpressionPaths() {
                // H1RO-style avatar expressions with authentic mouth shapes and phonemes
                // Base expressions that will be varied generatively
                this.baseExpressions = {
                    neutral: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 120, r: 16 },
                        rightEye: { cx: 295, cy: 120, r: 16 },
                        mouth: { cx: 200, cy: 180, rx: 20, ry: 4 }, // Neutral closed mouth
                        headRotation: 0
                    },
                    idle: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 120, r: 16 },
                        rightEye: { cx: 295, cy: 120, r: 16 },
                        mouth: { cx: 200, cy: 180, rx: 18, ry: 3 }, // Slightly relaxed mouth
                        headRotation: 0
                    },
                    happy: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 115, r: 12 }, // Squinted with joy
                        rightEye: { cx: 295, cy: 115, r: 12 },
                        mouth: { cx: 200, cy: 185, rx: 25, ry: 12 }, // Smiling open mouth
                        headRotation: 5
                    },
                    sad: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 102, cy: 125, r: 18 }, // Droopy, larger
                        rightEye: { cx: 292, cy: 125, r: 18 },
                        mouth: { cx: 200, cy: 190, rx: 15, ry: 6 }, // Downturned mouth
                        headRotation: -8
                    },
                    surprised: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 118, r: 22 }, // Wide open
                        rightEye: { cx: 295, cy: 118, r: 22 },
                        mouth: { cx: 200, cy: 185, rx: 12, ry: 18 }, // Open "O" shape
                        headRotation: 2
                    },
                    thinking: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 122, r: 14 }, // Focused, smaller
                        rightEye: { cx: 295, cy: 122, r: 14 },
                        mouth: { cx: 200, cy: 182, rx: 8, ry: 3 }, // Small contemplative mouth
                        headRotation: -5
                    },
                    speaking: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 119, r: 15 }, // Engaged
                        rightEye: { cx: 295, cy: 119, r: 15 },
                        mouth: { cx: 200, cy: 184, rx: 18, ry: 10 }, // Active speaking mouth
                        headRotation: 3
                    },
                    confused: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 104, cy: 121, r: 15 }, // Asymmetrical confusion
                        rightEye: { cx: 296, cy: 119, r: 17 },
                        mouth: { cx: 200, cy: 183, rx: 6, ry: 8 }, // Small confused "o"
                        headRotation: -2
                    },
                    determined: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 118, r: 13 }, // Narrowed focus
                        rightEye: { cx: 295, cy: 118, r: 13 },
                        mouth: { cx: 200, cy: 182, rx: 22, ry: 3 }, // Tight determined line
                        headRotation: 4
                    },
                    concerned: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 103, cy: 123, r: 17 }, // Worried, closer together
                        rightEye: { cx: 293, cy: 123, r: 17 },
                        mouth: { cx: 200, cy: 188, rx: 14, ry: 8 }, // Worried frown
                        headRotation: -6
                    },
                    amazed: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 117, r: 24 }, // Very wide, wonder-filled
                        rightEye: { cx: 295, cy: 117, r: 24 },
                        mouth: { cx: 200, cy: 185, rx: 15, ry: 20 }, // Large amazed "O"
                        headRotation: 4
                    },
                    skeptical: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 103, cy: 119, r: 14 }, // Asymmetrical doubt
                        rightEye: { cx: 297, cy: 121, r: 16 },
                        mouth: { cx: 200, cy: 183, rx: 18, ry: 4 }, // Slight smirk
                        headRotation: -3
                    },
                    ecstatic: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 112, r: 10 }, // Very squinted with extreme joy
                        rightEye: { cx: 295, cy: 112, r: 10 },
                        mouth: { cx: 200, cy: 188, rx: 30, ry: 15 }, // Wide ecstatic smile
                        headRotation: 8
                    }
                };
                
                // PARAMETRIC MOUTH SYSTEM - Single vector shape with full control
                // Instead of multiple SVG files, use controllable parameters
                this.mouthParameters = {
                    // Base mouth position and size
                    centerX: 200,
                    centerY: 180,
                    
                    // Core shape controls
                    width: 40,          // Overall mouth width
                    height: 8,          // Overall mouth height (opening)
                    curve: 0,           // Smile curve: -1 (frown) to +1 (smile)
                    asymmetry: 0,       // Left/right asymmetry: -1 to +1
                    lipThickness: 3,    // How thick the lips appear
                    
                    // Advanced controls
                    cornerHeight: 0,    // Corner elevation: -1 (down) to +1 (up)
                    innerCurve: 0.5,    // Inner mouth curve intensity
                    compression: 0,     // Horizontal compression for "oo" sounds
                    stretch: 0,         // Vertical stretch for "ah" sounds
                    
                    // Articulation details
                    teethVisible: false,    // Show teeth line
                    tongueVisible: false,   // Show tongue
                    tonguePosition: 0.5,    // Tongue position 0-1
                };
                
                // Enhanced phoneme definitions using parameters instead of SVG files
                this.phonemeMouths = {
                    // REST - Relaxed neutral mouth
                    rest: {
                        width: 30, height: 3, curve: 0, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0, compression: 0, stretch: 0
                    },
                    
                    // CLOSED - Lips pressed together (m, b, p)
                    closed: {
                        width: 35, height: 1, curve: 0, asymmetry: 0,
                        lipThickness: 4, cornerHeight: 0, compression: 0.2, stretch: 0
                    },
                    
                    // OPEN - Wide open mouth (ah, aa, a)
                    open: {
                        width: 45, height: 20, curve: 0.2, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0.1, compression: 0, stretch: 0.3,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.3
                    },
                    
                    // EE - Wide smile shape (ee, i)
                    ee: {
                        width: 50, height: 8, curve: 0.6, asymmetry: 0,
                        lipThickness: 1, cornerHeight: 0.3, compression: 0, stretch: -0.1,
                        teethVisible: true
                    },
                    
                    // OH - Rounded medium opening (oh, o)
                    oh: {
                        width: 35, height: 15, curve: 0.1, asymmetry: 0,
                        lipThickness: 3, cornerHeight: 0, compression: 0.1, stretch: 0.1,
                        tongueVisible: true, tonguePosition: 0.4
                    },
                    
                    // OO - Small rounded opening (oo, u)
                    oo: {
                        width: 25, height: 12, curve: 0, asymmetry: 0,
                        lipThickness: 4, cornerHeight: 0, compression: 0.4, stretch: 0,
                        teethVisible: false
                    },
                    
                    // S - Narrow gap for sibilants (s, z, sh)
                    s: {
                        width: 40, height: 6, curve: 0.1, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0.1, compression: 0, stretch: -0.2,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.7
                    },
                    
                    // FV - Lip to teeth contact (f, v)
                    fv: {
                        width: 35, height: 4, curve: -0.1, asymmetry: 0.1,
                        lipThickness: 3, cornerHeight: -0.1, compression: 0.1, stretch: 0,
                        teethVisible: true
                    },
                    
                    // TH - Tongue between teeth (th)
                    th: {
                        width: 38, height: 5, curve: 0, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0, compression: 0, stretch: 0,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.8
                    },
                    
                    // L - Lateral tongue position (l, r)
                    l: {
                        width: 40, height: 10, curve: 0.2, asymmetry: 0.1,
                        lipThickness: 2, cornerHeight: 0.1, compression: 0, stretch: 0,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.6
                    },
                    
                    // K - Back of tongue raised (k, g, ng)
                    k: {
                        width: 35, height: 8, curve: 0, asymmetry: 0,
                        lipThickness: 3, cornerHeight: 0, compression: 0, stretch: 0.1,
                        tongueVisible: true, tonguePosition: 0.2
                    },
                    
                    // T - Tongue tip to alveolar ridge (t, d, n)
                    t: {
                        width: 38, height: 6, curve: 0.1, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0.05, compression: 0, stretch: 0,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.75
                    }
                };
                
                // Create the parametric mouth shape
                this.createParametricMouth();
                
                // Generate current expressions with variations
                this.generateExpressionVariations();
            }

            generateExpressionVariations() {
                this.expressions = {};
                
                Object.keys(this.baseExpressions).forEach(emotion => {
                    const base = this.baseExpressions[emotion];
                    
                    // Add small random variations while preserving emotion
                    const variation = {
                        head: base.head,
                        leftEye: {
                            cx: base.leftEye.cx + this.randomVariation(2), 
                            cy: base.leftEye.cy + this.randomVariation(1), 
                            r: Math.max(5, base.leftEye.r + this.randomVariation(1))
                        },
                        rightEye: {
                            cx: base.rightEye.cx + this.randomVariation(2), 
                            cy: base.rightEye.cy + this.randomVariation(1), 
                            r: Math.max(5, base.rightEye.r + this.randomVariation(1))
                        },
                        mouth: {
                            cx: base.mouth.cx + this.randomVariation(1), 
                            cy: base.mouth.cy + this.randomVariation(0.5), 
                            rx: Math.max(3, base.mouth.rx + this.randomVariation(0.5)), 
                            ry: Math.max(1, base.mouth.ry + this.randomVariation(0.5))
                        },
                        headRotation: base.headRotation + this.randomVariation(0.5)
                    };
                    
                    this.expressions[emotion] = variation;
                });
            }

            randomVariation(maxRange) {
                return (Math.random() - 0.5) * 2 * maxRange;
            }

            initializeAnimationSystem() {
                this.setInitialPaths();
                this.setupMorphingAnimations();
            }

            setInitialPaths() {
                const idle = this.expressions.idle;
                this.head.setAttribute('d', idle.head);
                this.leftEye.setAttribute('cx', idle.leftEye.cx);
                this.leftEye.setAttribute('cy', idle.leftEye.cy);
                this.leftEye.setAttribute('r', idle.leftEye.r);
                this.rightEye.setAttribute('cx', idle.rightEye.cx);
                this.rightEye.setAttribute('cy', idle.rightEye.cy);
                this.rightEye.setAttribute('r', idle.rightEye.r);
                this.mouth.setAttribute('cx', idle.mouth.cx);
                this.mouth.setAttribute('cy', idle.mouth.cy);
                this.mouth.setAttribute('rx', idle.mouth.rx);
                this.mouth.setAttribute('ry', idle.mouth.ry);
            }

            setupMorphingAnimations() {
                this.morphFunctions = {};
                
                Object.keys(this.expressions).forEach(emotion => {
                    this.morphFunctions[emotion] = {};
                    const paths = this.expressions[emotion];
                    
                    // Only setup morphing for head (path) - eyes and mouth use GSAP attribute animation
                    ['head'].forEach(element => {
                        this.morphFunctions[emotion][element] = {};
                        
                        Object.keys(this.expressions).forEach(targetEmotion => {
                            if (emotion !== targetEmotion) {
                                try {
                                    this.morphFunctions[emotion][element][targetEmotion] = 
                                        flubber.interpolate(paths[element], this.expressions[targetEmotion][element]);
                                } catch (e) {
                                    console.warn(`Failed to create morph from ${emotion} to ${targetEmotion} for ${element}`);
                                }
                            }
                        });
                    });
                });
            }

            setExpression(emotion, immediate = false) {
                if (immediate) {
                    this.setImmediateExpression(emotion);
                } else {
                    this.transitionToExpression(emotion);
                }
            }

            setImmediateExpression(emotion) {
                if (!this.expressions[emotion]) return;
                
                const paths = this.expressions[emotion];
                this.head.setAttribute('d', paths.head);
                this.leftEye.setAttribute('cx', paths.leftEye.cx);
                this.leftEye.setAttribute('cy', paths.leftEye.cy);
                this.leftEye.setAttribute('r', paths.leftEye.r);
                this.rightEye.setAttribute('cx', paths.rightEye.cx);
                this.rightEye.setAttribute('cy', paths.rightEye.cy);
                this.rightEye.setAttribute('r', paths.rightEye.r);
                this.mouth.setAttribute('cx', paths.mouth.cx);
                this.mouth.setAttribute('cy', paths.mouth.cy);
                this.mouth.setAttribute('rx', paths.mouth.rx);
                this.mouth.setAttribute('ry', paths.mouth.ry);
                
                this.currentEmotion = emotion;
            }

            transitionToExpression(emotion) {
                if (emotion === this.currentEmotion || this.isAnimating) return;
                
                this.isAnimating = true;
                const duration = this.options.animationDuration;
                
                // Regenerate expressions with slight variations each time
                this.generateExpressionVariations();
                
                const timeline = gsap.timeline({
                    onComplete: () => {
                        this.currentEmotion = emotion;
                        this.isAnimating = false;
                    }
                });
                
                // Get target expression
                const targetExpression = this.expressions[emotion];
                
                // Animate head rotation
                timeline.to(this.head, {
                    duration: duration / 1000 * 2,
                    rotation: targetExpression.headRotation,
                    ease: "cubic-bezier(0, 0, 0.58, 1)",
                    transformOrigin: "center center"
                }, 0);
                
                // Animate head morphing
                const headMorphFunction = this.morphFunctions[this.currentEmotion]?.head?.[emotion];
                if (headMorphFunction) {
                    const headElement = this.head;
                    timeline.to({}, {
                        duration: duration / 1000 * 2,
                        ease: "cubic-bezier(0, 0, 0.58, 1)",
                        onUpdate: function() {
                            const progress = timeline.progress();
                            const newPath = headMorphFunction(progress);
                            headElement.setAttribute('d', newPath);
                        }
                    }, 0);
                }
                
                // Animate left eye
                timeline.to(this.leftEye, {
                    duration: duration / 1000 * 2,
                    attr: {
                        cx: targetExpression.leftEye.cx,
                        cy: targetExpression.leftEye.cy,
                        r: targetExpression.leftEye.r
                    },
                    ease: "cubic-bezier(0, 0, 0.58, 1)"
                }, 0);
                
                // Animate right eye
                timeline.to(this.rightEye, {
                    duration: duration / 1000 * 2,
                    attr: {
                        cx: targetExpression.rightEye.cx,
                        cy: targetExpression.rightEye.cy,
                        r: targetExpression.rightEye.r
                    },
                    ease: "cubic-bezier(0, 0, 0.58, 1)"
                }, 0);
                
                // Animate mouth
                timeline.to(this.mouth, {
                    duration: duration / 1000 * 2,
                    attr: {
                        cx: targetExpression.mouth.cx,
                        cy: targetExpression.mouth.cy,
                        rx: targetExpression.mouth.rx,
                        ry: targetExpression.mouth.ry
                    },
                    ease: "cubic-bezier(0, 0, 0.58, 1)"
                }, 0);
                
                // Add subtle scaling animation for eyes and mouth
                [this.leftEye, this.rightEye, this.mouth].forEach((element, index) => {
                    timeline.to(element, {
                        duration: duration / 1000,
                        scale: 1.05,
                        ease: "cubic-bezier(0, 0, 0.58, 1)",
                        transformOrigin: "center center"
                    }, index * 0.005);
                    
                    timeline.to(element, {
                        duration: duration / 1000,
                        scale: 1.0,
                        ease: "cubic-bezier(0, 0, 0.58, 1)",
                        transformOrigin: "center center"
                    }, duration / 1000 + index * 0.005);
                });
            }

            analyzeSentiment(text) {
                if (typeof Sentiment !== 'undefined') {
                    const sentiment = new Sentiment();
                    const result = sentiment.analyze(text);
                    const emotion = this.determineEmotion(result);
                    const confidence = Math.abs(result.score) / Math.max(text.split(' ').length, 1);
                    
                    if (confidence > 0.3) {
                        this.setExpression(emotion);
                    }
                    
                    return { emotion, confidence, result };
                }
                return null;
            }

            determineEmotion(sentimentResult) {
                const score = sentimentResult.score;
                const comparative = sentimentResult.comparative;
                const tokens = sentimentResult.tokens.map(t => t.toLowerCase());
                
                // Check for specific emotional keywords first
                if (tokens.some(token => ['amazing', 'incredible', 'fantastic', 'awesome'].includes(token))) {
                    return Math.random() > 0.5 ? 'amazed' : 'ecstatic';
                }
                
                if (tokens.some(token => ['confused', 'puzzled', 'unclear', 'what', 'huh'].includes(token))) {
                    return 'confused';
                }
                
                if (tokens.some(token => ['determined', 'focused', 'will', 'must', 'definitely'].includes(token))) {
                    return 'determined';
                }
                
                if (tokens.some(token => ['worried', 'concerned', 'anxious', 'nervous'].includes(token))) {
                    return 'concerned';
                }
                
                if (tokens.some(token => ['skeptical', 'doubt', 'really', 'sure', 'hmm'].includes(token))) {
                    return 'skeptical';
                }
                
                // Enhanced sentiment-based emotion detection
                if (score > 5) return 'ecstatic';
                if (score > 3) return 'happy';
                if (score > 1) return Math.random() > 0.5 ? 'happy' : 'amazed';
                
                if (score < -5) return Math.random() > 0.5 ? 'sad' : 'concerned';
                if (score < -3) return 'sad';
                if (score < -1) return Math.random() > 0.5 ? 'sad' : 'concerned';
                
                if (Math.abs(comparative) > 0.5) return 'surprised';
                if (Math.abs(comparative) > 0.3) return Math.random() > 0.5 ? 'surprised' : 'amazed';
                
                if (tokens.some(token => 
                    ['think', 'consider', 'maybe', 'perhaps', 'wondering', 'hmm'].includes(token)
                )) {
                    return Math.random() > 0.5 ? 'thinking' : 'confused';
                }
                
                return 'neutral';
            }

            setupPerformanceMonitoring() {
                this.performanceMetrics = {
                    animationFrames: 0,
                    lastFrameTime: performance.now(),
                    avgFrameTime: 16.67
                };
                
                this.startPerformanceMonitoring();
            }

            startPerformanceMonitoring() {
                const monitor = () => {
                    const currentTime = performance.now();
                    const frameTime = currentTime - this.performanceMetrics.lastFrameTime;
                    
                    this.performanceMetrics.avgFrameTime = 
                        (this.performanceMetrics.avgFrameTime * 0.9) + (frameTime * 0.1);
                    
                    this.performanceMetrics.lastFrameTime = currentTime;
                    this.performanceMetrics.animationFrames++;
                    
                    requestAnimationFrame(monitor);
                };
                
                requestAnimationFrame(monitor);
            }

            checkServerStatus() {
                fetch('/api/status')
                    .then(response => response.json())
                    .then(data => {
                        const statusEl = document.getElementById('apiStatus');
                        statusEl.textContent = `‚úÖ Connected to ${data.server_type || 'server'} - Mode: ${data.demo_mode ? 'Demo' : 'Production'}`;
                    })
                    .catch(error => {
                        const statusEl = document.getElementById('apiStatus');
                        statusEl.textContent = '‚ö†Ô∏è Server connection failed';
                    });
            }

            getPerformanceMetrics() {
                return {
                    ...this.performanceMetrics,
                    fps: 1000 / this.performanceMetrics.avgFrameTime,
                    currentEmotion: this.currentEmotion,
                    queueLength: 0,
                    quality: this.options.highQuality ? 'High' : 'Standard'
                };
            }

            // PARAMETRIC MOUTH ANIMATION for real-time lip sync
            updateMouthForPhoneme(phoneme, duration, scaleMultiplier) {
                console.log(`Parametric mouth: ${phoneme}, duration: ${duration}, scale: ${scaleMultiplier}`);
                
                if (!this.phonemeMouths[phoneme]) {
                    console.log(`No mouth parameters found for phoneme: ${phoneme}`);
                    return;
                }
                
                // Get base parameters for this phoneme
                const baseParams = this.phonemeMouths[phoneme];
                console.log(`Base parameters for ${phoneme}:`, baseParams);
                
                // Apply generative variations for organic feel
                const variationParams = this.generateParametricVariation(phoneme, baseParams, scaleMultiplier);
                
                // Smooth transition to new mouth shape using GSAP
                this.morphParametricMouth(variationParams, duration);
                
                // Add secondary facial animations for enhanced realism
                this.addParametricSecondaryAnimations(phoneme, duration);
            }

            // GENERATIVE PARAMETRIC VARIATION SYSTEM
            generateParametricVariation(phoneme, baseParams, scaleMultiplier) {
                // Start with base parameters
                const variation = { ...baseParams };
                
                // Apply scale multiplier to width and height
                variation.width *= scaleMultiplier;
                variation.height *= scaleMultiplier;
                
                // Add time-based organic variations (breathing, micro-movements)
                const timeOffset = Date.now() / 2000; // Slow organic variation
                const breathingFactor = Math.sin(timeOffset * 3) * 0.05; // 5% breathing variation
                
                // Phoneme-specific organic rules
                switch(phoneme) {
                    case 'open':
                        // Open vowels: Add jaw drop variation
                        variation.height *= (1 + breathingFactor * 2); // More pronounced breathing
                        variation.stretch += Math.sin(timeOffset * 4) * 0.1;
                        break;
                        
                    case 'ee':
                        // Smile shape: Add corner elevation variation
                        variation.cornerHeight += Math.cos(timeOffset * 5) * 0.1;
                        variation.curve += Math.sin(timeOffset * 3) * 0.1;
                        break;
                        
                    case 'oo':
                        // Rounded: Add compression pulsing
                        variation.compression += Math.sin(timeOffset * 6) * 0.1;
                        variation.lipThickness *= (1 + breathingFactor);
                        break;
                        
                    case 's':
                        // Sibilants: Add micro-asymmetry
                        variation.asymmetry += Math.sin(timeOffset * 8) * 0.05;
                        break;
                        
                    case 'fv':
                        // Fricatives: Add lip tension variation
                        variation.lipThickness *= (1 + Math.cos(timeOffset * 7) * 0.2);
                        variation.asymmetry += Math.sin(timeOffset * 4) * 0.1;
                        break;
                        
                    default:
                        // General organic variation
                        variation.width *= (1 + breathingFactor * 0.5);
                        variation.height *= (1 + breathingFactor * 0.3);
                        break;
                }
                
                // Add random micro-variations for ultra-realistic feel (30% chance)
                if (Math.random() > 0.7) {
                    variation.asymmetry += (Math.random() - 0.5) * 0.1;
                    variation.cornerHeight += (Math.random() - 0.5) * 0.05;
                    variation.curve += (Math.random() - 0.5) * 0.1;
                }
                
                console.log(`Generated parametric variation for ${phoneme}:`, variation);
                return variation;
            }

            // SMOOTH PARAMETRIC MORPHING
            morphParametricMouth(targetParams, duration) {
                if (!this.mouthGroup) {
                    console.warn('Parametric mouth not initialized');
                    return;
                }
                
                // Create intermediate parameters for smooth interpolation
                const startParams = { ...this.mouthParameters };
                
                // Use GSAP to smoothly interpolate between current and target parameters
                gsap.to(this.mouthParameters, {
                    duration: duration,
                    width: targetParams.width,
                    height: targetParams.height,
                    curve: targetParams.curve,
                    asymmetry: targetParams.asymmetry,
                    lipThickness: targetParams.lipThickness,
                    cornerHeight: targetParams.cornerHeight,
                    compression: targetParams.compression,
                    stretch: targetParams.stretch,
                    ease: "power2.inOut",
                    onUpdate: () => {
                        // Update the mouth shape every frame during the transition
                        this.updateParametricMouth(this.mouthParameters);
                    },
                    onComplete: () => {
                        // Ensure final state is exact
                        this.updateParametricMouth(targetParams);
                        
                        // Update teeth and tongue visibility
                        if (targetParams.teethVisible !== undefined) {
                            this.mouthParameters.teethVisible = targetParams.teethVisible;
                        }
                        if (targetParams.tongueVisible !== undefined) {
                            this.mouthParameters.tongueVisible = targetParams.tongueVisible;
                            this.mouthParameters.tonguePosition = targetParams.tonguePosition || 0.5;
                        }
                        this.updateParametricMouth(this.mouthParameters);
                    }
                });
                
                console.log(`Started parametric morph from [${startParams.width}x${startParams.height}] to [${targetParams.width}x${targetParams.height}]`);
            }

            // PARAMETRIC SECONDARY ANIMATIONS
            addParametricSecondaryAnimations(phoneme, duration) {
                // Enhanced facial coordination for different phoneme types
                
                // Nostril movement for nasal consonants
                if (['closed', 't', 'k'].includes(phoneme)) {
                    // Subtle nostril flare animation via eye movement
                    gsap.to([this.leftEye, this.rightEye], {
                        duration: duration * 0.3,
                        attr: { cy: `+=${-0.5}` }, // Slight upward movement
                        ease: "power2.out",
                        yoyo: true,
                        repeat: 1
                    });
                }
                
                // Eye dilation for vowel emphasis
                if (['open', 'ee', 'oh', 'oo'].includes(phoneme)) {
                    const currentRadius = parseInt(this.leftEye.getAttribute('r'));
                    gsap.to([this.leftEye, this.rightEye], {
                        duration: duration * 0.2,
                        attr: { r: `+=${1}` }, // Slight dilation
                        ease: "power2.out",
                        yoyo: true,
                        repeat: 1
                    });
                }
                
                // Subtle head movement for emphasis (20/80 rule - body mechanics)
                if (['s', 'fv', 'th'].includes(phoneme)) {
                    gsap.to(this.faceGroup, {
                        duration: 0.15,
                        rotation: Math.random() > 0.5 ? 0.5 : -0.5,
                        ease: "power2.out",
                        yoyo: true,
                        repeat: 1
                    });
                }
            }

            // Add phoneme animation for realistic speaking
            animatePhonemes(text) {
                if (!text) return;
                
                // Simple phoneme mapping based on text
                const phonemes = this.textToPhonemes(text);
                const timeline = gsap.timeline();
                
                phonemes.forEach((phoneme, index) => {
                    const mouthShape = this.phonemeMouths[phoneme] || this.phonemeMouths.medium_open;
                    
                    timeline.to(this.mouth, {
                        duration: 0.15,
                        attr: {
                            cx: mouthShape.cx,
                            cy: mouthShape.cy,
                            rx: mouthShape.rx,
                            ry: mouthShape.ry
                        },
                        ease: "power2.out"
                    }, index * 0.1);
                });
                
                // Return to speaking mouth shape
                timeline.to(this.mouth, {
                    duration: 0.2,
                    attr: {
                        cx: this.expressions.speaking.mouth.cx,
                        cy: this.expressions.speaking.mouth.cy,
                        rx: this.expressions.speaking.mouth.rx,
                        ry: this.expressions.speaking.mouth.ry
                    },
                    ease: "power2.out"
                });
            }
            
            textToPhonemes(text) {
                // Enhanced phoneme mapping with co-articulation consideration
                const phonemeMap = {
                    // Bilabials
                    'b': 'closed', 'm': 'closed', 'p': 'closed',
                    
                    // Fricatives and Sibilants  
                    's': 'small_open', 'z': 'small_open', 'sh': 'small_open', 
                    'ch': 'small_open', 'j': 'small_open',
                    'f': 'teeth_lower', 'v': 'teeth_lower',
                    
                    // Alveolars
                    'd': 'medium_open', 't': 'medium_open', 'n': 'medium_open',
                    
                    // Liquids
                    'l': 'tongue_tip', 'r': 'tongue_tip',
                    
                    // Fricatives
                    'th': 'tongue_tip', // both voiced and unvoiced
                    
                    // Velars
                    'k': 'tongue_back', 'g': 'tongue_back', 'ng': 'tongue_back',
                    
                    // Glottals and Aspirated
                    'h': 'aspirated', 'wh': 'aspirated',
                    
                    // Vowels - High
                    'i': 'tall_narrow', 'ee': 'tall_narrow', 
                    'ih': 'tall_open', 'eh': 'tall_open',
                    
                    // Vowels - Mid
                    'e': 'medium_open', 'uh': 'medium_open',
                    'er': 'medium_open', 'ur': 'medium_open',
                    
                    // Vowels - Low  
                    'a': 'wide_open', 'ah': 'wide_open', 'o': 'wide_open',
                    'aa': 'very_wide', 'aw': 'very_wide',
                    
                    // Rounded vowels
                    'u': 'round_small', 'oo': 'round_medium', 
                    'w': 'round_medium',
                    
                    // Diphthongs
                    'ay': 'diphthong_start', 'oy': 'diphthong_start', 
                    'ow': 'diphthong_start', 'ey': 'diphthong_start'
                };
                
                // Simple word-to-phoneme mapping for common words
                const wordPhonemes = {
                    'the': ['th', 'uh'],
                    'and': ['ah', 'n', 'd'],
                    'hello': ['h', 'eh', 'l', 'ow'],
                    'world': ['w', 'er', 'l', 'd'],
                    'how': ['h', 'ow'],
                    'are': ['ah', 'r'],
                    'you': ['y', 'oo'],
                    'what': ['wh', 'ah', 't'],
                    'when': ['wh', 'eh', 'n'],
                    'where': ['wh', 'eh', 'r'],
                    'this': ['th', 'ih', 's'],
                    'that': ['th', 'ah', 't'],
                    'with': ['w', 'ih', 'th'],
                    'will': ['w', 'ih', 'l'],
                    'can': ['k', 'ah', 'n'],
                    'could': ['k', 'oo', 'd'],
                    'should': ['sh', 'oo', 'd'],
                    'would': ['w', 'oo', 'd']
                };
                
                const phonemes = [];
                const words = text.toLowerCase().split(/\s+/);
                
                for (let word of words) {
                    // Clean word of punctuation
                    const cleanWord = word.replace(/[^\w]/g, '');
                    
                    if (wordPhonemes[cleanWord]) {
                        // Use pre-mapped phonemes for known words
                        phonemes.push(...wordPhonemes[cleanWord]);
                    } else {
                        // Fall back to character-based mapping
                        for (let char of cleanWord) {
                            phonemes.push(phonemeMap[char] || 'medium_open');
                        }
                    }
                    
                    // Add brief pause between words
                    if (words.indexOf(word) < words.length - 1) {
                        phonemes.push('rest');
                    }
                }
                
                return phonemes;
            }

            // PARAMETRIC MOUTH CREATION SYSTEM
            createParametricMouth() {
                // Remove the old ellipse mouth if it exists
                if (this.mouth) {
                    this.mouth.remove();
                }
                
                // Create a group to hold all mouth elements
                this.mouthGroup = document.createElementNS('http://www.w3.org/2000/svg', 'g');
                this.mouthGroup.setAttribute('id', 'parametric-mouth');
                this.mouthGroup.style.transformOrigin = '200px 180px';
                
                // Main mouth shape (vector path)
                this.mouthPath = document.createElementNS('http://www.w3.org/2000/svg', 'path');
                this.mouthPath.setAttribute('fill', '#8B0000'); // Dark red mouth interior
                this.mouthPath.setAttribute('stroke', '#4A0000');
                this.mouthPath.setAttribute('stroke-width', '1');
                this.mouthPath.setAttribute('id', 'mouth-shape');
                
                // Upper lip path
                this.upperLip = document.createElementNS('http://www.w3.org/2000/svg', 'path');
                this.upperLip.setAttribute('fill', '#000000');
                this.upperLip.setAttribute('stroke', 'none');
                this.upperLip.setAttribute('id', 'upper-lip');
                
                // Lower lip path  
                this.lowerLip = document.createElementNS('http://www.w3.org/2000/svg', 'path');
                this.lowerLip.setAttribute('fill', '#000000');
                this.lowerLip.setAttribute('stroke', 'none');
                this.lowerLip.setAttribute('id', 'lower-lip');
                
                // Teeth (optional, for open mouth positions)
                this.teeth = document.createElementNS('http://www.w3.org/2000/svg', 'rect');
                this.teeth.setAttribute('fill', '#FFFFFF');
                this.teeth.setAttribute('stroke', '#E0E0E0');
                this.teeth.setAttribute('stroke-width', '0.5');
                this.teeth.setAttribute('id', 'teeth');
                this.teeth.style.display = 'none'; // Hidden by default
                
                // Tongue (optional, for certain phonemes)
                this.tongue = document.createElementNS('http://www.w3.org/2000/svg', 'ellipse');
                this.tongue.setAttribute('fill', '#FF69B4'); // Pink tongue
                this.tongue.setAttribute('stroke', 'none');
                this.tongue.setAttribute('id', 'tongue');
                this.tongue.style.display = 'none'; // Hidden by default
                
                // Assemble mouth group
                this.mouthGroup.appendChild(this.mouthPath);
                this.mouthGroup.appendChild(this.teeth);
                this.mouthGroup.appendChild(this.tongue);
                this.mouthGroup.appendChild(this.upperLip);
                this.mouthGroup.appendChild(this.lowerLip);
                
                // Add to face
                this.faceGroup.appendChild(this.mouthGroup);
                
                // Set initial mouth shape
                this.updateParametricMouth(this.phonemeMouths.rest);
                
                console.log('Parametric mouth system created');
            }

            // UPDATE PARAMETRIC MOUTH SHAPE
            updateParametricMouth(params) {
                if (!this.mouthGroup) return;
                
                // Merge with current parameters
                const currentParams = { ...this.mouthParameters, ...params };
                
                // Calculate derived values
                const centerX = currentParams.centerX;
                const centerY = currentParams.centerY;
                const width = currentParams.width;
                const height = currentParams.height;
                const curve = currentParams.curve;
                const asymmetry = currentParams.asymmetry;
                const lipThickness = currentParams.lipThickness;
                const cornerHeight = currentParams.cornerHeight;
                const compression = currentParams.compression;
                const stretch = currentParams.stretch;
                
                // Apply compression and stretch
                const effectiveWidth = width * (1 - compression * 0.5);
                const effectiveHeight = height * (1 + stretch * 0.5);
                
                // Calculate corner positions with asymmetry
                const leftCornerX = centerX - effectiveWidth / 2;
                const rightCornerX = centerX + effectiveWidth / 2;
                const leftCornerY = centerY + (cornerHeight * 10) + (asymmetry * 3);
                const rightCornerY = centerY + (cornerHeight * 10) - (asymmetry * 3);
                
                // Calculate control points for curves
                const curveFactor = curve * effectiveWidth * 0.3;
                const upperCurveY = centerY - effectiveHeight / 2 - curveFactor;
                const lowerCurveY = centerY + effectiveHeight / 2 + curveFactor;
                
                // CREATE MAIN MOUTH PATH (interior)
                if (effectiveHeight > 2) {
                    // Open mouth - create interior shape
                    const mouthPath = `
                        M ${leftCornerX} ${leftCornerY}
                        Q ${centerX} ${upperCurveY} ${rightCornerX} ${rightCornerY}
                        Q ${centerX} ${lowerCurveY} ${leftCornerX} ${leftCornerY}
                        Z
                    `;
                    this.mouthPath.setAttribute('d', mouthPath);
                    this.mouthPath.style.display = 'block';
                } else {
                    // Closed mouth - hide interior
                    this.mouthPath.style.display = 'none';
                }
                
                // CREATE LIP PATHS
                const lipHalfThickness = lipThickness / 2;
                
                // Upper lip
                const upperLipPath = `
                    M ${leftCornerX} ${leftCornerY - lipHalfThickness}
                    Q ${centerX} ${upperCurveY - lipHalfThickness} ${rightCornerX} ${rightCornerY - lipHalfThickness}
                    Q ${centerX} ${upperCurveY + lipHalfThickness} ${leftCornerX} ${leftCornerY + lipHalfThickness}
                    Z
                `;
                this.upperLip.setAttribute('d', upperLipPath);
                
                // Lower lip (only if mouth is not too closed)
                if (effectiveHeight > 1) {
                    const lowerLipPath = `
                        M ${leftCornerX} ${leftCornerY + lipHalfThickness}
                        Q ${centerX} ${lowerCurveY - lipHalfThickness} ${rightCornerX} ${rightCornerY + lipHalfThickness}
                        Q ${centerX} ${lowerCurveY + lipHalfThickness} ${leftCornerX} ${leftCornerY + lipHalfThickness}
                        Z
                    `;
                    this.lowerLip.setAttribute('d', lowerLipPath);
                    this.lowerLip.style.display = 'block';
                } else {
                    this.lowerLip.style.display = 'none';
                }
                
                // TEETH VISIBILITY
                if (currentParams.teethVisible && effectiveHeight > 8) {
                    const teethWidth = effectiveWidth * 0.8;
                    const teethHeight = Math.min(effectiveHeight * 0.3, 6);
                    this.teeth.setAttribute('x', centerX - teethWidth / 2);
                    this.teeth.setAttribute('y', centerY - effectiveHeight / 2);
                    this.teeth.setAttribute('width', teethWidth);
                    this.teeth.setAttribute('height', teethHeight);
                    this.teeth.style.display = 'block';
                } else {
                    this.teeth.style.display = 'none';
                }
                
                // TONGUE VISIBILITY
                if (currentParams.tongueVisible && effectiveHeight > 5) {
                    const tongueWidth = effectiveWidth * 0.6;
                    const tongueHeight = Math.min(effectiveHeight * 0.4, 8);
                    const tongueY = centerY + (currentParams.tonguePosition - 0.5) * effectiveHeight;
                    
                    this.tongue.setAttribute('cx', centerX);
                    this.tongue.setAttribute('cy', tongueY);
                    this.tongue.setAttribute('rx', tongueWidth / 2);
                    this.tongue.setAttribute('ry', tongueHeight / 2);
                    this.tongue.style.display = 'block';
                } else {
                    this.tongue.style.display = 'none';
                }
                
                // Store current parameters
                this.mouthParameters = currentParams;
            }
        }

        // Global variables
        let expressionSystem;
        let performanceInterval;
        let audioProcessor; // New audio processing system
        
        // Audio processing class for real-time lip sync (PROFESSIONAL TECHNIQUES)
        class RealTimeAudioProcessor {
            constructor() {
                this.audioContext = null;
                this.analyser = null;
                this.microphone = null;
                this.isListening = false;
                this.dataArray = null;
                this.bufferLength = 0;
                this.lastPhoneme = 'rest';
                this.phonemeHistory = []; // For anticipatory timing
                this.detectedPhonemes = new Set();
                this.frameCounter = 0;
                
                // Professional timing settings
                this.anticipationFrames = 2; // Place shapes 1-2 frames early
                this.holdFrames = 3; // Hold plosives for 3 frames
                
                // Timing control for smoother transitions
                this.lastChangeTime = 0; // Track when we last changed phonemes
                
                // Core 5 shapes for 60-70% coverage (Limited Articulation Principle)
                this.coreShapes = ['rest', 'open', 'closed', 'ee', 'oh'];
                this.coreShapeUsage = 0;
                this.totalShapeUsage = 0;
                
                // SVG cache for faster loading
                this.svgCache = new Map();
                this.preloadSVGs();
                
                // SPEECH-TO-TEXT SYSTEM for enhanced phoneme detection
                this.speechRecognition = null;
                this.useSpeechRecognition = false; // Toggle between frequency analysis and speech recognition
                this.speechBuffer = '';
                this.speechPhonemeQueue = [];
                this.lastSpeechUpdate = 0;
                
                this.initializeSpeechRecognition();
            }
            
            async preloadSVGs() {
                // Preload all SVG visemes for faster real-time performance
                const svgFiles = [
                    'assets/ah.svg', 'assets/e.svg', 'assets/oh.svg', 'assets/w-oo.svg',
                    'assets/s.svg', 'assets/f.svg', 'assets/l.svg', 'assets/d.svg', 'assets/uh.svg'
                ];
                
                console.log('Starting SVG preload...');
                
                for (const file of svgFiles) {
                    try {
                        console.log(`Loading ${file}...`);
                        const response = await fetch(file);
                        if (!response.ok) {
                            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                        }
                        const svgText = await response.text();
                        this.svgCache.set(file, svgText);
                        console.log(`‚úì Preloaded: ${file} (${svgText.length} characters)`);
                    } catch (error) {
                        console.error(`‚úó Failed to preload: ${file}`, error);
                    }
                }
                console.log(`SVG cache ready: ${this.svgCache.size} files loaded`);
                console.log('Cached files:', Array.from(this.svgCache.keys()));
            }
            
            // SPEECH-TO-TEXT ENHANCED PHONEME DETECTION
            initializeSpeechRecognition() {
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    this.speechRecognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                    this.speechRecognition.continuous = true;
                    this.speechRecognition.interimResults = true;
                    this.speechRecognition.lang = 'en-US';
                    
                    this.speechRecognition.onresult = (event) => {
                        this.processSpeechResult(event);
                    };
                    
                    this.speechRecognition.onerror = (event) => {
                        console.warn('Speech recognition error:', event.error);
                        // Fall back to frequency analysis
                        this.useSpeechRecognition = false;
                    };
                    
                    console.log('Speech recognition initialized');
                } else {
                    console.log('Speech recognition not supported, using frequency analysis only');
                }
            }
            
            processSpeechResult(event) {
                let finalTranscript = '';
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Use interim results for real-time lip sync
                const currentText = interimTranscript || finalTranscript;
                if (currentText && currentText !== this.speechBuffer) {
                    this.speechBuffer = currentText;
                    
                    // Convert text to phoneme sequence
                    const phonemes = this.textToPhonemeSequence(currentText);
                    this.speechPhonemeQueue = phonemes;
                    this.lastSpeechUpdate = Date.now();
                    
                    console.log(`Speech detected: "${currentText}" -> [${phonemes.join(', ')}]`);
                }
            }
            
            textToPhonemeSequence(text) {
                // ENHANCED PHONEME MAPPING with professional linguistic rules
                // Based on Carnegie Mellon University Pronouncing Dictionary patterns
                
                const phoneticRules = {
                    // Vowel patterns (most expressive for animation)
                    'ee': 'ee', 'ea': 'ee', 'e_e': 'ee', 'i_e': 'ee', 'ie': 'ee',
                    'ai': 'open', 'ay': 'open', 'a_e': 'open', 'ei': 'open',
                    'aa': 'open', 'ah': 'open', 'a': 'open',
                    'oo': 'oo', 'ou': 'oo', 'u_e': 'oo', 'ue': 'oo', 'ew': 'oo',
                    'oh': 'oh', 'oa': 'oh', 'o_e': 'oh', 'ow': 'oh', 'oe': 'oh',
                    'uh': 'oh', 'u': 'oh', 'o': 'oh',
                    
                    // Consonant clusters (place of articulation)
                    'sh': 's', 'ch': 's', 'th': 'th', 'ph': 'fv', 'gh': 'fv',
                    'ng': 'k', 'nk': 'k', 'ck': 'k',
                    'mb': 'closed', 'mp': 'closed',
                    'nd': 't', 'nt': 't', 'st': 's', 'sp': 'closed',
                    
                    // Individual consonants
                    'b': 'closed', 'm': 'closed', 'p': 'closed', 'w': 'oo',
                    'f': 'fv', 'v': 'fv',
                    't': 't', 'd': 't', 'n': 't', 's': 's', 'z': 's',
                    'l': 'l', 'r': 'l',
                    'k': 'k', 'g': 'k', 'h': 'open',
                    
                    // Silent letters (don't generate phonemes)
                    'silent': ['e$', 'gh$', 'mb$', 'kn^', 'wr^', 'ps^']
                };
                
                // Word-level phoneme sequences for common words
                const wordPhonemes = {
                    'hello': ['k', 'open', 'l', 'oh'],
                    'world': ['oo', 'l', 't'],
                    'how': ['k', 'open', 'oo'],
                    'are': ['open', 'l'],
                    'you': ['oo'],
                    'the': ['th', 'open'],
                    'and': ['open', 't'],
                    'this': ['th', 'ee', 's'],
                    'that': ['th', 'open', 't'],
                    'with': ['oo', 'ee', 'th'],
                    'what': ['oo', 'open', 't'],
                    'when': ['oo', 'open', 't'],
                    'where': ['oo', 'open', 'l'],
                    'good': ['k', 'oo', 't'],
                    'great': ['k', 'ee', 't'],
                    'nice': ['t', 'open', 's'],
                    'fine': ['fv', 'open', 't'],
                    'okay': ['oh', 'open'],
                    'yes': ['ee', 's'],
                    'no': ['t', 'oh'],
                    'maybe': ['open', 'ee'],
                    'sure': ['s', 'l'],
                    'thanks': ['th', 'open', 'k', 's'],
                    'please': ['fv', 'ee', 's'],
                    'sorry': ['s', 'oh', 'ee'],
                    'excuse': ['k', 's', 'oo', 's']
                };
                
                const phonemes = [];
                const words = text.toLowerCase().replace(/[^\w\s]/g, '').split(/\s+/);
                
                for (let word of words) {
                    if (wordPhonemes[word]) {
                        // Use pre-mapped high-quality phonemes
                        phonemes.push(...wordPhonemes[word]);
                    } else {
                        // Phonetic analysis for unknown words
                        const wordPhonemes = this.analyzeWordPhonetically(word, phoneticRules);
                        phonemes.push(...wordPhonemes);
                    }
                    
                    // Add brief pause between words
                    phonemes.push('rest');
                }
                
                return phonemes;
            }
            
            analyzeWordPhonetically(word, phoneticRules) {
                const phonemes = [];
                let i = 0;
                
                while (i < word.length) {
                    let matched = false;
                    
                    // Try to match multi-character patterns first
                    for (let len = 3; len > 0; len--) {
                        const substr = word.substr(i, len);
                        if (phoneticRules[substr]) {
                            phonemes.push(phoneticRules[substr]);
                            i += len;
                            matched = true;
                            break;
                        }
                    }
                    
                    if (!matched) {
                        // Single character fallback
                        const char = word[i];
                        if (phoneticRules[char]) {
                            phonemes.push(phoneticRules[char]);
                        } else if ('aeiou'.includes(char)) {
                            phonemes.push('open'); // Default vowel
                        } else if (char.match(/[bcdfghjklmnpqrstvwxyz]/)) {
                            phonemes.push('closed'); // Default consonant
                        }
                        i++;
                    }
                }
                
                return phonemes;
            }
            
            // HYBRID PHONEME DETECTION: Combines speech recognition and frequency analysis
            getEnhancedPhoneme() {
                if (this.useSpeechRecognition && this.speechPhonemeQueue.length > 0) {
                    // Use speech-to-text phonemes with timing
                    const timeSinceUpdate = Date.now() - this.lastSpeechUpdate;
                    const phonemeIndex = Math.floor(timeSinceUpdate / 150); // 150ms per phoneme
                    
                    if (phonemeIndex < this.speechPhonemeQueue.length) {
                        return this.speechPhonemeQueue[phonemeIndex];
                    } else {
                        // Speech sequence finished, clear queue
                        this.speechPhonemeQueue = [];
                        return 'rest';
                    }
                } else {
                    // Fall back to frequency analysis
                    return this.detectPhoneme(this.dataArray);
                }
            }
            
            async startListening() {
                try {
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    
                    // Request microphone access
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: { 
                            echoCancellation: true,
                            noiseSuppression: true,
                            sampleRate: 16000 // Lower sample rate for performance
                        } 
                    });
                    
                    this.microphone = this.audioContext.createMediaStreamSource(stream);
                    this.analyser = this.audioContext.createAnalyser();
                    
                    // Optimize for performance
                    this.analyser.fftSize = 512; // Smaller FFT for speed
                    this.analyser.smoothingTimeConstant = 0.8; // Professional smoothing
                    
                    this.bufferLength = this.analyser.frequencyBinCount;
                    this.dataArray = new Uint8Array(this.bufferLength);
                    
                    this.microphone.connect(this.analyser);
                    this.isListening = true;
                    
                    // Start speech recognition if available
                    if (this.speechRecognition && this.useSpeechRecognition) {
                        try {
                            this.speechRecognition.start();
                            console.log('Speech recognition started for enhanced phoneme detection');
                        } catch (error) {
                            console.warn('Could not start speech recognition:', error);
                            this.useSpeechRecognition = false;
                        }
                    }
                    
                    this.processAudio();
                    console.log('Real-time audio processing started with enhanced phoneme detection');
                    
                } catch (error) {
                    console.error('Error starting audio:', error);
                }
            }
            
            processAudio() {
                if (!this.isListening) return;
                
                this.analyser.getByteFrequencyData(this.dataArray);
                this.frameCounter++;
                
                // ENHANCED PHONEME DETECTION: Use hybrid system
                const detectedPhoneme = this.getEnhancedPhoneme();
                
                // Add to history for anticipatory timing (1-2 frames early)
                this.phonemeHistory.push({
                    phoneme: detectedPhoneme,
                    frame: this.frameCounter,
                    timestamp: Date.now()
                });
                
                // Keep only recent history (last 10 frames)
                if (this.phonemeHistory.length > 10) {
                    this.phonemeHistory.shift();
                }
                
                // Apply anticipatory timing - use phoneme from 2 frames ago
                let phonemeToApply = detectedPhoneme;
                if (this.phonemeHistory.length >= this.anticipationFrames) {
                    const anticipatedIndex = this.phonemeHistory.length - this.anticipationFrames;
                    phonemeToApply = this.phonemeHistory[anticipatedIndex].phoneme;
                }
                
                // Professional core shape prioritization (60-70% rule)
                this.totalShapeUsage++;
                if (this.coreShapes.includes(phonemeToApply)) {
                    this.coreShapeUsage++;
                }
                
                // IMPROVED TIMING: Add minimum hold time and debouncing
                const currentTime = Date.now();
                const timeSinceLastChange = currentTime - (this.lastChangeTime || 0);
                const minimumHoldTime = 150; // Reduced from 200ms to 150ms for better responsiveness
                
                // Only update if phoneme changed AND enough time has passed
                if (phonemeToApply !== this.lastPhoneme && timeSinceLastChange > minimumHoldTime) {
                    // Track detected phonemes
                    this.detectedPhonemes.add(phonemeToApply);
                    
                    // Calculate core shape usage percentage
                    const corePercentage = Math.round((this.coreShapeUsage / this.totalShapeUsage) * 100);
                    
                    // Enhanced debug display with professional metrics
                    const audioStatus = document.getElementById('audioStatus');
                    if (audioStatus && audioStatus.style.display !== 'none') {
                        const phonemeList = Array.from(this.detectedPhonemes).join(', ');
                        const detectionMode = this.useSpeechRecognition ? 'Speech-to-Text' : 'Frequency Analysis';
                        audioStatus.textContent = `üé§ ${detectionMode} Lip Sync - Current: ${phonemeToApply} | Core Usage: ${corePercentage}% | Detected: (${this.detectedPhonemes.size}/12) ${phonemeList}`;
                    }
                    
                    // SMOOTH TRANSITION DURATIONS for visible morphing
                    let duration = 0.25; // Base duration for smooth morphing
                    
                    // Professional hold timing for different phoneme types
                    if (['closed', 't', 'k'].includes(phonemeToApply)) {
                        duration = 0.35; // Longer for plosives to see the mouth position
                    }
                    
                    // Vowels get medium duration
                    if (['open', 'ee', 'oh', 'oo'].includes(phonemeToApply)) {
                        duration = 0.3; // Medium duration for vowels
                    }
                    
                    // Fricatives need shorter duration for rapid articulation
                    if (['s', 'fv', 'th'].includes(phonemeToApply)) {
                        duration = 0.2; // Faster for fricatives
                    }
                    
                    // Stylized exaggeration for cartoon appeal
                    let scaleMultiplier = 1.0;
                    if (['open', 'ee', 'oh'].includes(phonemeToApply)) {
                        scaleMultiplier = 1.15; // 15% larger for expressive vowels
                    }
                    
                    console.log(`Enhanced audio calling updateMouthForPhoneme with: ${phonemeToApply}, duration: ${duration}, scale: ${scaleMultiplier}, mode: ${this.useSpeechRecognition ? 'Speech' : 'Frequency'}`);
                    
                    // Call the expression system's mouth shape update method directly
                    if (expressionSystem && expressionSystem.updateMouthForPhoneme) {
                        expressionSystem.updateMouthForPhoneme(phonemeToApply, duration, scaleMultiplier);
                        
                        // Secondary facial animations
                        if (expressionSystem.addSecondaryAnimations) {
                            expressionSystem.addSecondaryAnimations(phonemeToApply);
                        }
                    } else {
                        console.warn('Expression system or updateMouthForPhoneme method not available');
                    }
                    
                    this.lastPhoneme = phonemeToApply;
                    this.lastChangeTime = currentTime; // Track when we last changed
                }
                
                // High frequency processing for real-time feel
                requestAnimationFrame(() => this.processAudio());
            }
            
            detectPhoneme(frequencyData) {
                // ENHANCED CARTOON-OPTIMIZED PHONEME DETECTION
                // Professional frequency analysis with temporal smoothing and prediction
                const sampleRate = this.audioContext.sampleRate;
                const binSize = sampleRate / this.analyser.fftSize;
                
                // Enhanced frequency band analysis (more precise ranges)
                let veryHighEnergy = 0;    // 4000+ Hz - sharp sibilants (s, sh)
                let highEnergy = 0;        // 2000-4000 Hz - fricatives (f, th)
                let upperMidEnergy = 0;    // 1000-2000 Hz - vowel formants
                let midEnergy = 0;         // 400-1000 Hz - fundamental vowel frequencies
                let lowMidEnergy = 0;      // 150-400 Hz - voiced consonants
                let lowEnergy = 0;         // 80-150 Hz - vocal cord vibration
                let totalEnergy = 0;
                
                for (let i = 0; i < frequencyData.length; i++) {
                    const frequency = i * binSize;
                    const amplitude = frequencyData[i] / 255.0;
                    
                    totalEnergy += amplitude;
                    
                    if (frequency >= 4000) {
                        veryHighEnergy += amplitude;
                    } else if (frequency >= 2000) {
                        highEnergy += amplitude;
                    } else if (frequency >= 1000) {
                        upperMidEnergy += amplitude;
                    } else if (frequency >= 400) {
                        midEnergy += amplitude;
                    } else if (frequency >= 150) {
                        lowMidEnergy += amplitude;
                    } else if (frequency >= 80) {
                        lowEnergy += amplitude;
                    }
                }
                
                // Normalize energies by frequency band size
                const numBins = frequencyData.length;
                veryHighEnergy = veryHighEnergy / (numBins * 0.2); // Fewer high freq bins
                highEnergy = highEnergy / (numBins * 0.25);
                upperMidEnergy = upperMidEnergy / (numBins * 0.25);
                midEnergy = midEnergy / (numBins * 0.3);
                lowMidEnergy = lowMidEnergy / (numBins * 0.3);
                lowEnergy = lowEnergy / (numBins * 0.35);
                totalEnergy /= numBins;
                
                // TEMPORAL SMOOTHING: Add history for stability
                if (!this.energyHistory) {
                    this.energyHistory = [];
                }
                
                this.energyHistory.push({
                    total: totalEnergy,
                    veryHigh: veryHighEnergy,
                    high: highEnergy,
                    upperMid: upperMidEnergy,
                    mid: midEnergy,
                    lowMid: lowMidEnergy,
                    low: lowEnergy,
                    timestamp: Date.now()
                });
                
                // Keep only last 5 frames for smoothing
                if (this.energyHistory.length > 5) {
                    this.energyHistory.shift();
                }
                
                // Calculate smoothed averages
                const smoothed = {
                    total: this.energyHistory.reduce((sum, frame) => sum + frame.total, 0) / this.energyHistory.length,
                    veryHigh: this.energyHistory.reduce((sum, frame) => sum + frame.veryHigh, 0) / this.energyHistory.length,
                    high: this.energyHistory.reduce((sum, frame) => sum + frame.high, 0) / this.energyHistory.length,
                    upperMid: this.energyHistory.reduce((sum, frame) => sum + frame.upperMid, 0) / this.energyHistory.length,
                    mid: this.energyHistory.reduce((sum, frame) => sum + frame.mid, 0) / this.energyHistory.length,
                    lowMid: this.energyHistory.reduce((sum, frame) => sum + frame.lowMid, 0) / this.energyHistory.length,
                    low: this.energyHistory.reduce((sum, frame) => sum + frame.low, 0) / this.energyHistory.length
                };
                
                // SILENCE DETECTION: More sophisticated
                if (smoothed.total < 0.06 || (smoothed.high < 0.05 && smoothed.mid < 0.05 && smoothed.low < 0.05)) {
                    return 'rest';
                }
                
                // ENHANCED PHONEME CLASSIFICATION
                // Professional linguistic rules based on acoustic phonetics
                
                // 1. SIBILANTS: Sharp, high-frequency noise
                if (smoothed.veryHigh > 0.15 && smoothed.high > 0.2) {
                    if (smoothed.veryHigh > 0.25) {
                        return 's'; // Strong sibilants (s, z, sh, zh)
                    } else {
                        return 's'; // Weaker sibilants, still use S shape
                    }
                }
                
                // 2. FRICATIVES: Mid-high frequency noise
                if (smoothed.high > 0.18 && smoothed.upperMid > 0.15) {
                    if (smoothed.upperMid > smoothed.mid) {
                        return 'fv'; // Labiodental fricatives (f, v)
                    } else {
                        return 'th'; // Dental fricatives (th)
                    }
                }
                
                // 3. VOWEL CLASSIFICATION: Based on formant patterns
                if (smoothed.mid > 0.25 || smoothed.upperMid > 0.2) {
                    // F1/F2 frequency relationship determines vowel type
                    const f1Energy = smoothed.mid; // First formant (jaw height)
                    const f2Energy = smoothed.upperMid; // Second formant (tongue position)
                    
                    if (f2Energy > f1Energy) {
                        // High F2 = front vowels
                        if (f1Energy < 0.3) {
                            return 'ee'; // High front vowels (i, e)
                        } else {
                            return 'open'; // Mid-low front vowels (ae, a)
                        }
                    } else {
                        // Low F2 = back vowels
                        if (f1Energy < 0.35) {
                            return 'oo'; // High back vowels (u, o)
                        } else {
                            return 'oh'; // Mid-low back vowels (aw, ah)
                        }
                    }
                }
                
                // 4. CONSONANT CLASSIFICATION: Based on voicing and place
                if (smoothed.lowMid > 0.2 || smoothed.low > 0.15) {
                    const voicing = smoothed.low; // Fundamental frequency indicates voicing
                    const articulation = smoothed.lowMid; // Mid frequencies show place of articulation
                    
                    if (articulation > voicing * 1.5) {
                        // Strong articulation = alveolar consonants
                        return Math.random() > 0.5 ? 't' : 'l'; // t/d/n or l/r
                    } else if (voicing > 0.2) {
                        // Strong voicing = bilabial or velar
                        return Math.random() > 0.5 ? 'closed' : 'k'; // m/b/p or k/g/ng
                    } else {
                        return 'l'; // Liquids and approximants
                    }
                }
                
                // 5. DYNAMIC FALLBACK: Use recent history for context
                if (this.phonemeHistory && this.phonemeHistory.length > 2) {
                    const recentPhonemes = this.phonemeHistory.slice(-3).map(h => h.phoneme);
                    
                    // If recent vowels, likely continuing vowel
                    if (recentPhonemes.some(p => ['open', 'ee', 'oh', 'oo'].includes(p))) {
                        const vowelOptions = ['open', 'ee', 'oh', 'oo'];
                        return vowelOptions[Math.floor(Math.random() * vowelOptions.length)];
                    }
                    
                    // If recent consonants, likely continuing consonant
                    if (recentPhonemes.some(p => ['closed', 't', 'k', 'l', 's', 'fv'].includes(p))) {
                        const consonantOptions = ['closed', 't', 'l'];
                        return consonantOptions[Math.floor(Math.random() * consonantOptions.length)];
                    }
                }
                
                // 6. FINAL FALLBACK: Expressive default based on energy
                if (smoothed.total > 0.12) {
                    // Moderate energy - cycle through most expressive visemes
                    const expressiveVisemes = ['open', 'oh', 'ee'];
                    const index = Math.floor((smoothed.total * 25 + Date.now() / 1500) % expressiveVisemes.length);
                    return expressiveVisemes[index];
                }
                
                // Very low energy
                return 'rest';
            }
            
            updateMouthShape(phoneme) {
                if (expressionSystem && expressionSystem.phonemeMouths[phoneme]) {
                    const mouthShape = expressionSystem.phonemeMouths[phoneme];
                    
                    // Track detected phonemes
                    this.detectedPhonemes.add(phoneme);
                    
                    // Enhanced debug display with more info
                    const audioStatus = document.getElementById('audioStatus');
                    if (audioStatus && audioStatus.style.display !== 'none') {
                        const phonemeList = Array.from(this.detectedPhonemes).join(', ');
                        audioStatus.textContent = `üé§ Audio Lip Sync Active - Current: ${phoneme} | Detected: (${this.detectedPhonemes.size}/12) ${phonemeList}`;
                    }
                    
                    // Fast mouth animation - no complex timeline
                    gsap.to(expressionSystem.mouth, {
                        duration: 0.1, // Very fast for real-time feel
                        attr: {
                            cx: mouthShape.cx,
                            cy: mouthShape.cy,
                            rx: mouthShape.rx,
                            ry: mouthShape.ry
                        },
                        ease: "none" // No easing for maximum speed
                    });
                }
            }
            
            stopListening() {
                this.isListening = false;
                if (this.microphone) {
                    this.microphone.disconnect();
                }
                if (this.audioContext) {
                    this.audioContext.close();
                }
                
                // Stop speech recognition
                if (this.speechRecognition && this.useSpeechRecognition) {
                    try {
                        this.speechRecognition.stop();
                        console.log('Speech recognition stopped');
                    } catch (error) {
                        console.warn('Error stopping speech recognition:', error);
                    }
                }
                
                console.log('Audio processing stopped');
            }
        }
        
        // Initialize the expression system
        document.addEventListener('DOMContentLoaded', function() {
            console.log('=== Initializing Expression System ===');
            
            expressionSystem = new HighQualityExpressionSystem('avatarContainer', {
                enableSentimentAnalysis: true,
                animationDuration: 200,
                highQuality: true
            });
            
            console.log('Expression system created:', !!expressionSystem);
            console.log('Phoneme mouths:', Object.keys(expressionSystem.phonemeMouths || {}));
            
            // Initialize audio processor
            audioProcessor = new RealTimeAudioProcessor();
            
            console.log('Audio processor created:', !!audioProcessor);
            
            setupEventListeners();
            
            // Set to idle state instead of cycling demo
            setTimeout(() => {
                console.log('Setting initial idle expression');
                expressionSystem.setExpression('idle');
            }, 500);
            
            console.log('=== Initialization Complete ===');
        });
        
        function setupEventListeners() {
            document.getElementById('sentimentToggle').addEventListener('change', function() {
                expressionSystem.options.enableSentimentAnalysis = this.checked;
            });
            
            document.getElementById('performanceToggle').addEventListener('change', function() {
                const metricsDiv = document.getElementById('performanceMetrics');
                if (this.checked) {
                    metricsDiv.style.display = 'block';
                    startPerformanceMonitoring();
                } else {
                    metricsDiv.style.display = 'none';
                    if (performanceInterval) {
                        clearInterval(performanceInterval);
                    }
                }
            });

            document.getElementById('qualityToggle').addEventListener('change', function() {
                expressionSystem.options.highQuality = this.checked;
                // Could implement dynamic quality switching here
            });
            
            // Real-time audio lip sync toggle
            document.getElementById('audioLipSyncToggle').addEventListener('change', async function() {
                const audioStatus = document.getElementById('audioStatus');
                
                if (this.checked) {
                    try {
                        await audioProcessor.startListening();
                        console.log('Real-time lip sync enabled');
                        // Set to speaking mode when audio is active
                        expressionSystem.setExpression('speaking');
                        // Show audio status
                        audioStatus.style.display = 'block';
                    } catch (error) {
                        console.error('Failed to start audio:', error);
                        this.checked = false;
                        alert('Microphone access denied or not available');
                        audioStatus.style.display = 'none';
                    }
                } else {
                    audioProcessor.stopListening();
                    console.log('Real-time lip sync disabled');
                    // Return to neutral when audio stops
                    expressionSystem.setExpression('neutral');
                    // Hide audio status
                    audioStatus.style.display = 'none';
                }
            });
            
            // Speech recognition mode toggle
            document.getElementById('speechRecognitionToggle').addEventListener('change', function() {
                if (audioProcessor) {
                    audioProcessor.useSpeechRecognition = this.checked;
                    
                    if (this.checked) {
                        // Start speech recognition if audio is already listening
                        if (audioProcessor.isListening && audioProcessor.speechRecognition) {
                            try {
                                audioProcessor.speechRecognition.start();
                                console.log('Speech recognition mode enabled');
                            } catch (error) {
                                console.warn('Could not start speech recognition:', error);
                                this.checked = false;
                                audioProcessor.useSpeechRecognition = false;
                                alert('Speech recognition not available. Using frequency analysis.');
                            }
                        }
                    } else {
                        // Stop speech recognition
                        if (audioProcessor.speechRecognition) {
                            try {
                                audioProcessor.speechRecognition.stop();
                                console.log('Speech recognition mode disabled - using frequency analysis');
                            } catch (error) {
                                console.warn('Error stopping speech recognition:', error);
                            }
                        }
                    }
                    
                    console.log(`Phoneme detection mode: ${this.checked ? 'Speech-to-Text' : 'Frequency Analysis'}`);
                }
            });
            
            document.getElementById('textInput').addEventListener('keypress', function(e) {
                if (e.key === 'Enter') {
                    analyzeText();
                }
            });
        }
        
        function setEmotion(emotion) {
            // Update active button
            document.querySelectorAll('.emotion-btn').forEach(btn => btn.classList.remove('active'));
            event.target.classList.add('active');
            
            // Set expression
            expressionSystem.setExpression(emotion);
        }
        
        function analyzeText() {
            const text = document.getElementById('textInput').value.trim();
            if (text) {
                const result = expressionSystem.analyzeSentiment(text);
                console.log('Sentiment analysis:', result);
                
                // Trigger phoneme animation if speaking-related
                if (result && (result.emotion === 'speaking' || text.length > 20)) {
                    setTimeout(() => {
                        expressionSystem.animatePhonemes(text);
                    }, 300);
                }
                
                document.getElementById('textInput').value = '';
            }
        }

        function fetchServerSentiment() {
            const text = document.getElementById('textInput').value.trim();
            if (!text) return;

            fetch('/api/analyze_sentiment', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ text: text })
            })
            .then(response => response.json())
            .then(data => {
                console.log('Server sentiment analysis:', data);
                if (data.emotion && data.confidence > 0.3) {
                    expressionSystem.setExpression(data.emotion);
                    
                    // Trigger phoneme animation if speaking-related
                    if (data.emotion === 'speaking' || text.length > 20) {
                        setTimeout(() => {
                            expressionSystem.animatePhonemes(text);
                        }, 300);
                    }
                }
                document.getElementById('textInput').value = '';
            })
            .catch(error => {
                console.error('Error:', error);
                // Fall back to client-side analysis
                analyzeText();
            });
        }
        
        function analyzePresetText(text) {
            document.getElementById('textInput').value = text;
            const result = expressionSystem.analyzeSentiment(text);
            console.log('Preset sentiment analysis:', result);
            
            setTimeout(() => {
                document.getElementById('textInput').value = '';
            }, 1000);
        }
        
        function startPerformanceMonitoring() {
            if (performanceInterval) clearInterval(performanceInterval);
            
            performanceInterval = setInterval(() => {
                const metrics = expressionSystem.getPerformanceMetrics();
                
                document.getElementById('fpsMetric').textContent = Math.round(metrics.fps);
                document.getElementById('emotionMetric').textContent = metrics.currentEmotion;
                document.getElementById('queueMetric').textContent = metrics.queueLength;
                document.getElementById('framesMetric').textContent = metrics.animationFrames;
                if (document.getElementById('qualityMetric')) {
                    document.getElementById('qualityMetric').textContent = metrics.quality;
                }
            }, 500);
        }

        function demoExpressions() {
            const emotions = ['happy', 'amazed', 'confused', 'determined', 'surprised', 'ecstatic', 'thinking', 'neutral'];
            let index = 0;
            
            const cycle = () => {
                expressionSystem.setExpression(emotions[index]);
                index = (index + 1) % emotions.length;
                
                setTimeout(cycle, 2500);
            };
            
            cycle();
        }
        
        // Keyboard shortcuts
        document.addEventListener('keydown', function(e) {
            if (e.altKey) {
                switch(e.key) {
                    case '1': setEmotion('neutral'); break;
                    case '2': setEmotion('happy'); break;
                    case '3': setEmotion('sad'); break;
                    case '4': setEmotion('surprised'); break;
                    case '5': setEmotion('thinking'); break;
                    case '6': setEmotion('speaking'); break;
                    case '7': setEmotion('confused'); break;
                    case '8': setEmotion('determined'); break;
                    case '9': setEmotion('concerned'); break;
                    case '0': setEmotion('amazed'); break;
                    case 'q': setEmotion('skeptical'); break;
                    case 'w': setEmotion('ecstatic'); break;
                }
            }
        });

        function testSVGMouth() {
            console.log('=== Testing Parametric Mouth System ===');
            console.log('Expression system exists:', !!expressionSystem);
            
            if (expressionSystem) {
                console.log('Phoneme parameters available:', Object.keys(expressionSystem.phonemeMouths || {}));
                
                // Test all parametric mouth shapes in sequence
                const parametricPhonemes = ['rest', 'closed', 'open', 'ee', 'oh', 'oo', 's', 'fv', 'th', 'l', 'k', 't'];
                let index = 0;
                
                function cycleNextMouth() {
                    if (index < parametricPhonemes.length) {
                        const phoneme = parametricPhonemes[index];
                        console.log(`=== Testing Parametric mouth ${index + 1}/${parametricPhonemes.length}: ${phoneme} ===`);
                        expressionSystem.updateMouthForPhoneme(phoneme, 0.3, 1.2);
                        index++;
                        setTimeout(cycleNextMouth, 1000); // Wait 1 second between each
                    } else {
                        console.log('=== Parametric mouth test complete ===');
                        // Return to neutral
                        expressionSystem.setExpression('idle');
                    }
                }
                
                cycleNextMouth();
            } else {
                console.error('Expression system not found');
            }
            
            if (audioProcessor) {
                console.log('SVG cache size:', audioProcessor.svgCache.size);
                console.log('Cached SVGs:', Array.from(audioProcessor.svgCache.keys()));
            } else {
                console.error('Audio processor not found');
            }
        }
    </script>
</body>
</html> 