<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fluid Expression System - Big Hero 6 Style Avatar (High Quality)</title>
    
    <!-- Core Libraries (no SocketIO) -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/gsap.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/flubber@0.4.2/build/flubber.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/sentiment@5.0.2/build/sentiment.min.js"></script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .demo-container {
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            max-width: 800px;
            width: 100%;
        }

        .title {
            text-align: center;
            color: #2c3e50;
            margin-bottom: 30px;
            font-size: 2.5em;
            font-weight: 300;
        }

        .subtitle {
            text-align: center;
            color: #7f8c8d;
            margin-bottom: 40px;
            font-size: 1.1em;
        }

        .avatar-container {
            display: flex;
            justify-content: center;
            margin-bottom: 40px;
            width: 100%; /* Full width container */
            max-width: 800px; /* Match demo container max-width */
        }

        #avatarContainer {
            width: 400px;
            height: 300px;
            min-width: 400px;  /* Prevent shrinking */
            max-width: 400px;  /* Prevent growing */
            min-height: 300px; /* Prevent shrinking */
            max-height: 300px; /* Prevent growing */
            border-radius: 20px;
            background: linear-gradient(145deg, #f0f0f0, #e6e6e6);
            border: 3px solid #e9ecef;
            overflow: hidden;
            position: relative;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 
                inset 0 2px 4px rgba(255,255,255,0.8),
                inset 0 -2px 4px rgba(0,0,0,0.1),
                0 8px 16px rgba(0,0,0,0.1);
            flex-shrink: 0; /* Prevent flexbox from shrinking this */
        }

        .avatar-face {
            width: 400px;    /* Fixed width */
            height: 300px;   /* Fixed height */
            max-width: 100%;
            max-height: 100%;
            filter: drop-shadow(0 2px 4px rgba(0,0,0,0.1));
        }

        .controls {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
            gap: 15px;
            margin-bottom: 30px;
        }

        .control-button {
            padding: 12px 20px;
            border: none;
            border-radius: 10px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .emotion-btn {
            background: #3498db;
            color: white;
        }

        .emotion-btn:hover {
            background: #2980b9;
            transform: translateY(-2px);
        }

        .emotion-btn.active {
            background: #e74c3c;
            box-shadow: 0 5px 15px rgba(231, 76, 60, 0.3);
        }

        .settings-section {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .settings-title {
            font-size: 1.2em;
            color: #2c3e50;
            margin-bottom: 15px;
            font-weight: 600;
        }

        .setting-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
            padding: 8px 0;
            border-bottom: 1px solid #e9ecef;
        }

        .setting-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
        }

        .toggle {
            position: relative;
            display: inline-block;
            width: 50px;
            height: 25px;
        }

        .toggle input {
            opacity: 0;
            width: 0;
            height: 0;
        }

        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #ccc;
            transition: .4s;
            border-radius: 25px;
        }

        .slider:before {
            position: absolute;
            content: "";
            height: 19px;
            width: 19px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }

        input:checked + .slider {
            background-color: #3498db;
        }

        input:checked + .slider:before {
            transform: translateX(25px);
        }

        .text-input-section {
            margin-bottom: 20px;
        }

        .text-input {
            width: 100%;
            padding: 15px;
            border: 2px solid #e9ecef;
            border-radius: 10px;
            font-size: 16px;
            margin-bottom: 10px;
            transition: border-color 0.3s ease;
        }

        .text-input:focus {
            outline: none;
            border-color: #3498db;
        }

        .analyze-btn {
            background: #27ae60;
            color: white;
            padding: 12px 25px;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            margin-right: 10px;
            margin-bottom: 10px;
            transition: background 0.3s ease;
        }

        .analyze-btn:hover {
            background: #229954;
        }

        .demo-text-samples {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 10px;
        }

        .sample-btn {
            background: #f39c12;
            color: white;
            padding: 8px 15px;
            border: none;
            border-radius: 6px;
            font-size: 12px;
            cursor: pointer;
            transition: background 0.3s ease;
        }

        .sample-btn:hover {
            background: #e67e22;
        }

        .performance-metrics {
            background: #2c3e50;
            color: white;
            padding: 15px;
            border-radius: 10px;
            margin-top: 20px;
        }

        .metric-row {
            display: flex;
            justify-content: space-between;
            padding: 5px 0;
            border-bottom: 1px solid #34495e;
        }

        .metric-row:last-child {
            border-bottom: none;
        }

        .status-indicator {
            text-align: center;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            background: #27ae60;
            color: white;
            font-weight: 600;
            height: 140px;
            box-sizing: border-box;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        .api-status {
            font-size: 12px;
            opacity: 0.8;
            margin-top: 5px;
        }

        .quality-indicator {
            text-align: center;
            padding: 8px;
            margin-bottom: 15px;
            border-radius: 6px;
            background: #3498db;
            color: white;
            font-size: 12px;
            font-weight: 600;
        }
    </style>
</head>
<body>
    <div class="demo-container">
        <h1 class="title">üé≠ Big Hero 6 Expression System</h1>
        <p class="subtitle">High-Quality Fluid Avatar Expressions with Real-time Sentiment Analysis</p>
        
        <div class="status-indicator" id="statusIndicator">
            <div>‚úÖ System Running in High Quality Mode</div>
            <div class="api-status" id="apiStatus">Connecting to server...</div>
            <div class="api-status" id="audioStatus" style="display: none;">üé§ Real-time Audio Lip Sync Active</div>
        </div>
        
        <div class="quality-indicator">
            üé® High Resolution SVG ‚Ä¢ Smooth Morphing ‚Ä¢ Enhanced Gradients ‚Ä¢ 60fps Target
        </div>
        
        <div class="avatar-container">
            <div id="avatarContainer"></div>
        </div>
        
        <div class="controls">
            <button class="control-button emotion-btn" onclick="setEmotion('neutral')">üòê Neutral</button>
            <button class="control-button emotion-btn active" onclick="setEmotion('idle')">üòå Idle</button>
            <button class="control-button emotion-btn" onclick="setEmotion('happy')">üòä Happy</button>
            <button class="control-button emotion-btn" onclick="setEmotion('sad')">üò¢ Sad</button>
            <button class="control-button emotion-btn" onclick="setEmotion('surprised')">üò≤ Surprised</button>
            <button class="control-button emotion-btn" onclick="setEmotion('thinking')">ü§î Thinking</button>
            <button class="control-button emotion-btn" onclick="setEmotion('speaking')">üó£Ô∏è Speaking</button>
            <button class="control-button emotion-btn" onclick="setEmotion('confused')">üòï Confused</button>
            <button class="control-button emotion-btn" onclick="setEmotion('determined')">üò§ Determined</button>
            <button class="control-button emotion-btn" onclick="setEmotion('concerned')">üòü Concerned</button>
            <button class="control-button emotion-btn" onclick="setEmotion('amazed')">ü§© Amazed</button>
            <button class="control-button emotion-btn" onclick="setEmotion('skeptical')">ü§® Skeptical</button>
            <button class="control-button emotion-btn" onclick="setEmotion('ecstatic')">ü•≥ Ecstatic</button>
            <button class="control-button emotion-btn" onclick="testSVGMouth()">üß™ Test Parametric Mouth</button>
        </div>
        
        <div class="settings-section">
            <div class="settings-title">üó£Ô∏è Voice Interaction System</div>
            
            <div class="setting-item">
                <span>üé§ Voice Input (Speech Recognition)</span>
                <label class="toggle">
                    <input type="checkbox" id="voiceInputToggle">
                    <span class="slider"></span>
                </label>
            </div>
            
            <div class="setting-item">
                <span>ü§ñ AI Response Generation</span>
                <label class="toggle">
                    <input type="checkbox" id="aiResponseToggle">
                    <span class="slider"></span>
                </label>
            </div>
            
            <div class="setting-item">
                <span>üîä TTS Output with Facial Animation</span>
                <label class="toggle">
                    <input type="checkbox" id="ttsOutputToggle">
                    <span class="slider"></span>
                </label>
            </div>
            
            <div class="setting-item">
                <span>üé≠ Auto-Expressions from Content</span>
                <label class="toggle">
                    <input type="checkbox" id="autoExpressionsToggle" checked>
                    <span class="slider"></span>
                </label>
            </div>
            
            <div style="margin-top: 15px; padding: 10px; background: #f8f9fa; border-radius: 8px;">
                <div style="font-weight: 600; margin-bottom: 8px;">Voice Interaction Status:</div>
                <div id="voiceInteractionStatus" style="font-size: 14px; color: #666;">System ready - toggle settings above to start</div>
            </div>
            
            <div style="display: flex; gap: 10px; margin-top: 15px;">
                <button class="control-button" style="background: #27ae60; color: white;" onclick="startVoiceInteraction()">
                    üéôÔ∏è Start Voice Chat
                </button>
                <button class="control-button" style="background: #e74c3c; color: white;" onclick="stopVoiceInteraction()">
                    ‚èπÔ∏è Stop Voice Chat
                </button>
                <button class="control-button" style="background: #3498db; color: white;" onclick="testTTSWithAnimation()">
                    üß™ Test TTS + Animation
                </button>
            </div>
        </div>
        
        <div class="settings-section">
            <h3 class="settings-title">‚öôÔ∏è System Settings</h3>
            <div class="setting-item">
                <span>Real-time Sentiment Analysis</span>
                <label class="toggle">
                    <input type="checkbox" id="sentimentToggle" checked>
                    <span class="slider"></span>
                </label>
            </div>
            <div class="setting-item">
                <span>Performance Monitoring</span>
                <label class="toggle">
                    <input type="checkbox" id="performanceToggle">
                    <span class="slider"></span>
                </label>
            </div>
            <div class="setting-item">
                <span>High Quality Rendering</span>
                <label class="toggle">
                    <input type="checkbox" id="qualityToggle" checked>
                    <span class="slider"></span>
                </label>
            </div>
            <div class="setting-item">
                <span>üé§ Real-time Audio Lip Sync</span>
                <label class="toggle">
                    <input type="checkbox" id="audioLipSyncToggle">
                    <span class="slider"></span>
                </label>
            </div>
            <div class="setting-item">
                <span>üó£Ô∏è Speech-to-Text Mode (Enhanced Accuracy)</span>
                <label class="toggle">
                    <input type="checkbox" id="speechRecognitionToggle">
                    <span class="slider"></span>
                </label>
            </div>
        </div>
        
        <div class="text-input-section">
            <input type="text" class="text-input" id="textInput" 
                   placeholder="Enter text to analyze sentiment and trigger expressions...">
            <button class="analyze-btn" onclick="analyzeText()">Analyze Sentiment</button>
            <button class="analyze-btn" onclick="fetchServerSentiment()">Send to Server</button>
            
            <div class="demo-text-samples">
                <button class="sample-btn" onclick="analyzePresetText('I am so excited about this new feature!')">üòä Happy Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('This is really disappointing and frustrating.')">üò¢ Sad Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('Wow, I never expected that to happen!')">üò≤ Surprised Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('Let me think about this carefully...')">ü§î Thinking Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('I am confused about what you mean.')">üòï Confused Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('I am determined to make this work!')">üò§ Determined Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('I am worried this might not work out.')">üòü Concerned Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('This is absolutely incredible and fantastic!')">ü§© Amazed Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('Hmm, I doubt that is really true.')">ü§® Skeptical Sample</button>
                <button class="sample-btn" onclick="analyzePresetText('This is the most amazing thing ever!')">ü•≥ Ecstatic Sample</button>
            </div>
        </div>
        
        <div class="performance-metrics" id="performanceMetrics" style="display: none;">
            <div class="metric-row">
                <span>FPS:</span>
                <span id="fpsMetric">--</span>
            </div>
            <div class="metric-row">
                <span>Current Emotion:</span>
                <span id="emotionMetric">neutral</span>
            </div>
            <div class="metric-row">
                <span>Queue Length:</span>
                <span id="queueMetric">0</span>
            </div>
            <div class="metric-row">
                <span>Animation Frames:</span>
                <span id="framesMetric">0</span>
            </div>
            <div class="metric-row">
                <span>Render Quality:</span>
                <span id="qualityMetric">High</span>
            </div>
        </div>
        
        <button class="control-button emotion-btn" onclick="toggleAudioDebug()">
            üé§ Toggle Audio Debug
        </button>
        
        <!-- NEW: Viseme Testing Section -->
        <div class="settings-section">
            <div class="settings-title">üó£Ô∏è Viseme Testing (19 Visemes)</div>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(120px, 1fr)); gap: 8px; margin-bottom: 15px;">
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('rest')">Rest</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('closed')">Closed (M,B,P)</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('open')">Open (A,Ah)</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('ee')">EE (I,E)</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('oh')">OH (O)</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('oo')">OO (U)</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('s')">S (S,Z,Sh)</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('fv')">F,V</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('th')">TH</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('l')">L,R</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('k')">K,G,NG</button>
                <button class="control-button" style="background: #27ae60; color: white; font-size: 12px;" onclick="testViseme('t')">T,D,N</button>
                <button class="control-button" style="background: #e74c3c; color: white; font-size: 12px;" onclick="testViseme('ay')">AY (New)</button>
                <button class="control-button" style="background: #e74c3c; color: white; font-size: 12px;" onclick="testViseme('aw')">AW (New)</button>
                <button class="control-button" style="background: #e74c3c; color: white; font-size: 12px;" onclick="testViseme('uh')">UH (New)</button>
                <button class="control-button" style="background: #e74c3c; color: white; font-size: 12px;" onclick="testViseme('w')">W (New)</button>
                <button class="control-button" style="background: #e74c3c; color: white; font-size: 12px;" onclick="testViseme('y')">Y (New)</button>
                <button class="control-button" style="background: #e74c3c; color: white; font-size: 12px;" onclick="testViseme('ch')">CH,J (New)</button>
                <button class="control-button" style="background: #e74c3c; color: white; font-size: 12px;" onclick="testViseme('r')">R (New)</button>
                <button class="control-button" style="background: #9b59b6; color: white; font-size: 12px;" onclick="testViseme('semiopen')">SemiOpen (New)</button>
            </div>
            
            <div style="display: flex; gap: 10px; margin-top: 15px;">
                <button class="control-button" style="background: #3498db; color: white;" onclick="testSmoothSequence()">
                    üåä Test Smooth Sequence
                </button>
                <button class="control-button" style="background: #f39c12; color: white;" onclick="testWordExample()">
                    üìù Test "Hello World"
                </button>
            </div>
        </div>
    </div>

    <script>
        // High Quality Expression System (Enhanced Version)
        class HighQualityExpressionSystem {
            constructor(containerId, options = {}) {
                this.container = document.getElementById(containerId);
                this.options = {
                    enableSentimentAnalysis: true,
                    animationDuration: 200,
                    highQuality: true,
                    ...options
                };
                
                this.currentEmotion = 'idle';
                this.isAnimating = false;
                
                this.init();
            }

            init() {
                this.createHighQualitySVGStructure();
                this.setupEnhancedExpressionPaths();
                this.initializeAnimationSystem();
                this.setupPerformanceMonitoring();
                this.checkServerStatus();
            }

            createHighQualitySVGStructure() {
                // Create high-resolution SVG based on original h1ro.svg design
                this.svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');
                this.svg.setAttribute('viewBox', '0 0 400 300'); // Adjusted for h1ro proportions
                this.svg.setAttribute('width', '400');
                this.svg.setAttribute('height', '300');
                this.svg.setAttribute('preserveAspectRatio', 'xMidYMid meet');
                this.svg.classList.add('avatar-face');
                this.svg.style.shapeRendering = 'geometricPrecision';
                this.svg.style.textRendering = 'optimizeLegibility';
                this.svg.style.overflow = 'visible';
                this.svg.style.display = 'block';
                
                // Create definitions for gradients and filters
                this.createSVGDefinitions();
                
                this.faceGroup = document.createElementNS('http://www.w3.org/2000/svg', 'g');
                this.faceGroup.classList.add('face-group');
                this.faceGroup.style.transformOrigin = '200px 150px'; // Center of 400x300 viewBox
                
                // Head with h1ro styling (oval shape)
                this.head = document.createElementNS('http://www.w3.org/2000/svg', 'path');
                this.head.setAttribute('fill', '#D9D9D9');
                this.head.setAttribute('stroke', '#bbb');
                this.head.setAttribute('stroke-width', '1');
                this.head.setAttribute('filter', 'url(#headGlow)');
                this.head.style.transformOrigin = '200px 120px'; // Center of head shape
                
                // Eyes with h1ro styling (perfect circles)
                this.leftEye = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
                this.leftEye.setAttribute('fill', '#000000');
                this.leftEye.setAttribute('filter', 'url(#eyeShadow)');
                this.leftEye.style.transformOrigin = '105px 120px'; // Center of left eye
                
                this.rightEye = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
                this.rightEye.setAttribute('fill', '#000000');
                this.rightEye.setAttribute('filter', 'url(#eyeShadow)');
                this.rightEye.style.transformOrigin = '295px 120px'; // Center of right eye
                
                // Mouth (replaces bridge) - oval shape like original h1ro
                this.mouth = document.createElementNS('http://www.w3.org/2000/svg', 'ellipse');
                this.mouth.setAttribute('fill', '#000000');
                this.mouth.setAttribute('filter', 'url(#mouthGlow)');
                this.mouth.style.transformOrigin = '200px 180px'; // Center of mouth area
                
                // Assemble SVG
                this.faceGroup.appendChild(this.head);
                this.faceGroup.appendChild(this.leftEye);
                this.faceGroup.appendChild(this.rightEye);
                this.faceGroup.appendChild(this.mouth);
                this.svg.appendChild(this.faceGroup);
                this.container.appendChild(this.svg);
            }

            createSVGDefinitions() {
                const defs = document.createElementNS('http://www.w3.org/2000/svg', 'defs');
                
                // Face gradient
                const faceGradient = document.createElementNS('http://www.w3.org/2000/svg', 'radialGradient');
                faceGradient.setAttribute('id', 'faceGradient');
                faceGradient.setAttribute('cx', '50%');
                faceGradient.setAttribute('cy', '40%');
                faceGradient.setAttribute('r', '60%');
                
                const stop1 = document.createElementNS('http://www.w3.org/2000/svg', 'stop');
                stop1.setAttribute('offset', '0%');
                stop1.setAttribute('stop-color', '#ffffff');
                stop1.setAttribute('stop-opacity', '0.9');
                
                const stop2 = document.createElementNS('http://www.w3.org/2000/svg', 'stop');
                stop2.setAttribute('offset', '100%');
                stop2.setAttribute('stop-color', '#ecf0f1');
                stop2.setAttribute('stop-opacity', '1');
                
                faceGradient.appendChild(stop1);
                faceGradient.appendChild(stop2);
                
                // Drop shadow filter
                const dropShadow = document.createElementNS('http://www.w3.org/2000/svg', 'filter');
                dropShadow.setAttribute('id', 'dropShadow');
                dropShadow.setAttribute('x', '-50%');
                dropShadow.setAttribute('y', '-50%');
                dropShadow.setAttribute('width', '200%');
                dropShadow.setAttribute('height', '200%');
                
                const shadow = document.createElementNS('http://www.w3.org/2000/svg', 'feDropShadow');
                shadow.setAttribute('dx', '0');
                shadow.setAttribute('dy', '2');
                shadow.setAttribute('stdDeviation', '2');
                shadow.setAttribute('flood-color', '#000000');
                shadow.setAttribute('flood-opacity', '0.2');
                
                dropShadow.appendChild(shadow);
                
                // Eye shadow filter
                const eyeShadow = document.createElementNS('http://www.w3.org/2000/svg', 'filter');
                eyeShadow.setAttribute('id', 'eyeShadow');
                
                const eyeShadowEffect = document.createElementNS('http://www.w3.org/2000/svg', 'feDropShadow');
                eyeShadowEffect.setAttribute('dx', '0');
                eyeShadowEffect.setAttribute('dy', '1');
                eyeShadowEffect.setAttribute('stdDeviation', '1');
                eyeShadowEffect.setAttribute('flood-color', '#000000');
                eyeShadowEffect.setAttribute('flood-opacity', '0.3');
                
                eyeShadow.appendChild(eyeShadowEffect);
                
                // Mouth glow filter
                const mouthGlow = document.createElementNS('http://www.w3.org/2000/svg', 'filter');
                mouthGlow.setAttribute('id', 'mouthGlow');
                
                const glow = document.createElementNS('http://www.w3.org/2000/svg', 'feGaussianBlur');
                glow.setAttribute('stdDeviation', '1');
                glow.setAttribute('result', 'coloredBlur');
                
                const merge = document.createElementNS('http://www.w3.org/2000/svg', 'feMerge');
                const mergeNode1 = document.createElementNS('http://www.w3.org/2000/svg', 'feMergeNode');
                mergeNode1.setAttribute('in', 'coloredBlur');
                const mergeNode2 = document.createElementNS('http://www.w3.org/2000/svg', 'feMergeNode');
                mergeNode2.setAttribute('in', 'SourceGraphic');
                
                merge.appendChild(mergeNode1);
                merge.appendChild(mergeNode2);
                mouthGlow.appendChild(glow);
                mouthGlow.appendChild(merge);
                
                defs.appendChild(faceGradient);
                defs.appendChild(dropShadow);
                defs.appendChild(eyeShadow);
                defs.appendChild(mouthGlow);
                this.svg.appendChild(defs);
            }

            setupEnhancedExpressionPaths() {
                // H1RO-style avatar expressions with authentic mouth shapes and phonemes
                // Base expressions that will be varied generatively
                this.baseExpressions = {
                    neutral: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 120, r: 16 },
                        rightEye: { cx: 295, cy: 120, r: 16 },
                        mouth: { cx: 200, cy: 180, rx: 20, ry: 4 }, // Neutral closed mouth
                        headRotation: 0
                    },
                    idle: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 120, r: 16 },
                        rightEye: { cx: 295, cy: 120, r: 16 },
                        mouth: { cx: 200, cy: 180, rx: 18, ry: 3 }, // Slightly relaxed mouth
                        headRotation: 0
                    },
                    happy: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 115, r: 12 }, // Squinted with joy
                        rightEye: { cx: 295, cy: 115, r: 12 },
                        mouth: { cx: 200, cy: 185, rx: 25, ry: 12 }, // Smiling open mouth
                        headRotation: 5
                    },
                    sad: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 102, cy: 125, r: 18 }, // Droopy, larger
                        rightEye: { cx: 292, cy: 125, r: 18 },
                        mouth: { cx: 200, cy: 190, rx: 15, ry: 6 }, // Downturned mouth
                        headRotation: -8
                    },
                    surprised: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 118, r: 22 }, // Wide open
                        rightEye: { cx: 295, cy: 118, r: 22 },
                        mouth: { cx: 200, cy: 185, rx: 12, ry: 18 }, // Open "O" shape
                        headRotation: 2
                    },
                    thinking: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 122, r: 14 }, // Focused, smaller
                        rightEye: { cx: 295, cy: 122, r: 14 },
                        mouth: { cx: 200, cy: 182, rx: 8, ry: 3 }, // Small contemplative mouth
                        headRotation: -5
                    },
                    speaking: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 119, r: 15 }, // Engaged
                        rightEye: { cx: 295, cy: 119, r: 15 },
                        mouth: { cx: 200, cy: 184, rx: 18, ry: 10 }, // Active speaking mouth
                        headRotation: 3
                    },
                    confused: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 104, cy: 121, r: 15 }, // Asymmetrical confusion
                        rightEye: { cx: 296, cy: 119, r: 17 },
                        mouth: { cx: 200, cy: 183, rx: 6, ry: 8 }, // Small confused "o"
                        headRotation: -2
                    },
                    determined: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 118, r: 13 }, // Narrowed focus
                        rightEye: { cx: 295, cy: 118, r: 13 },
                        mouth: { cx: 200, cy: 182, rx: 22, ry: 3 }, // Tight determined line
                        headRotation: 4
                    },
                    concerned: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 103, cy: 123, r: 17 }, // Worried, closer together
                        rightEye: { cx: 293, cy: 123, r: 17 },
                        mouth: { cx: 200, cy: 188, rx: 14, ry: 8 }, // Worried frown
                        headRotation: -6
                    },
                    amazed: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 117, r: 24 }, // Very wide, wonder-filled
                        rightEye: { cx: 295, cy: 117, r: 24 },
                        mouth: { cx: 200, cy: 185, rx: 15, ry: 20 }, // Large amazed "O"
                        headRotation: 4
                    },
                    skeptical: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 103, cy: 119, r: 14 }, // Asymmetrical doubt
                        rightEye: { cx: 297, cy: 121, r: 16 },
                        mouth: { cx: 200, cy: 183, rx: 18, ry: 4 }, // Slight smirk
                        headRotation: -3
                    },
                    ecstatic: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 112, r: 10 }, // Very squinted with extreme joy
                        rightEye: { cx: 295, cy: 112, r: 10 },
                        mouth: { cx: 200, cy: 188, rx: 30, ry: 15 }, // Wide ecstatic smile
                        headRotation: 8
                    },
                    
                    // MISSING EXPRESSIONS - Adding expressions referenced by voice interaction system
                    awake: {
                        head: 'M400 120C400 180.751 310.457 230 200 230C89.5431 230 0 180.751 0 120C0 59.2487 50.4 10 200 10C350 10 400 59.2487 400 120Z',
                        leftEye: { cx: 105, cy: 118, r: 18 }, // Alert, wide-open eyes
                        rightEye: { cx: 295, cy: 118, r: 18 },
                        mouth: { cx: 200, cy: 182, rx: 16, ry: 4 }, // Slightly open, attentive mouth
                        headRotation: 2
                    }
                };
                
                // PARAMETRIC MOUTH SYSTEM - Single vector shape with full control
                // Instead of multiple SVG files, use controllable parameters
                this.mouthParameters = {
                    // Base mouth position and size
                    centerX: 200,
                    centerY: 180,
                    
                    // Core shape controls
                    width: 40,          // Overall mouth width
                    height: 8,          // Overall mouth height (opening)
                    curve: 0,           // Smile curve: -1 (frown) to +1 (smile)
                    asymmetry: 0,       // Left/right asymmetry: -1 to +1
                    lipThickness: 3,    // How thick the lips appear
                    
                    // Advanced controls
                    cornerHeight: 0,    // Corner elevation: -1 (down) to +1 (up)
                    innerCurve: 0.5,    // Inner mouth curve intensity
                    compression: 0,     // Horizontal compression for "oo" sounds
                    stretch: 0,         // Vertical stretch for "ah" sounds
                    
                    // Articulation details
                    teethVisible: false,    // Show teeth line
                    tongueVisible: false,   // Show tongue
                    tonguePosition: 0.5,    // Tongue position 0-1
                };
                
                // Enhanced phoneme definitions using parameters instead of SVG files
                this.phonemeMouths = {
                    // REST - Relaxed neutral mouth
                    rest: {
                        width: 30, height: 3, curve: 0, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0, compression: 0, stretch: 0
                    },
                    
                    // CLOSED - Lips pressed together (m, b, p)
                    closed: {
                        width: 35, height: 1, curve: 0, asymmetry: 0,
                        lipThickness: 4, cornerHeight: 0, compression: 0.2, stretch: 0
                    },
                    
                    // OPEN - Wide open mouth (ah, aa, a)
                    open: {
                        width: 45, height: 20, curve: 0.2, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0.1, compression: 0, stretch: 0.3,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.3
                    },
                    
                    // EE - Wide smile shape (ee, i)
                    ee: {
                        width: 50, height: 8, curve: 0.6, asymmetry: 0,
                        lipThickness: 1, cornerHeight: 0.3, compression: 0, stretch: -0.1,
                        teethVisible: true
                    },
                    
                    // OH - Rounded medium opening (oh, o)
                    oh: {
                        width: 35, height: 15, curve: 0.1, asymmetry: 0,
                        lipThickness: 3, cornerHeight: 0, compression: 0.1, stretch: 0.1,
                        tongueVisible: true, tonguePosition: 0.4
                    },
                    
                    // OO - Small rounded opening (oo, u)
                    oo: {
                        width: 25, height: 12, curve: 0, asymmetry: 0,
                        lipThickness: 4, cornerHeight: 0, compression: 0.4, stretch: 0,
                        teethVisible: false
                    },
                    
                    // S - Narrow gap for sibilants (s, z, sh)
                    s: {
                        width: 40, height: 6, curve: 0.1, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0.1, compression: 0, stretch: -0.2,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.7
                    },
                    
                    // FV - Lip to teeth contact (f, v)
                    fv: {
                        width: 35, height: 4, curve: -0.1, asymmetry: 0.1,
                        lipThickness: 3, cornerHeight: -0.1, compression: 0.1, stretch: 0,
                        teethVisible: true
                    },
                    
                    // TH - Tongue between teeth (th)
                    th: {
                        width: 38, height: 5, curve: 0, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0, compression: 0, stretch: 0,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.8
                    },
                    
                    // L - Lateral tongue position (l, r)
                    l: {
                        width: 40, height: 10, curve: 0.2, asymmetry: 0.1,
                        lipThickness: 2, cornerHeight: 0.1, compression: 0, stretch: 0,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.6
                    },
                    
                    // K - Back of tongue raised (k, g, ng)
                    k: {
                        width: 35, height: 8, curve: 0, asymmetry: 0,
                        lipThickness: 3, cornerHeight: 0, compression: 0, stretch: 0.1,
                        tongueVisible: true, tonguePosition: 0.2
                    },
                    
                    // T - Tongue tip to alveolar ridge (t, d, n)
                    t: {
                        width: 38, height: 6, curve: 0.1, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0.05, compression: 0, stretch: 0,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.75
                    },

                    // EXPANDED VISEME SET FOR BETTER REALISM
                    
                    // AY - Diphthong "ay" as in "say" (transitional vowel)
                    ay: {
                        width: 42, height: 12, curve: 0.3, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0.2, compression: 0, stretch: 0.1,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.5
                    },
                    
                    // AW - "aw" as in "how" (back vowel with rounding)
                    aw: {
                        width: 32, height: 18, curve: 0.1, asymmetry: 0,
                        lipThickness: 3, cornerHeight: 0, compression: 0.2, stretch: 0.2,
                        tongueVisible: true, tonguePosition: 0.3
                    },
                    
                    // UH - Schwa/unstressed vowel (uh, er)
                    uh: {
                        width: 35, height: 8, curve: 0, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0, compression: 0.1, stretch: 0,
                        tongueVisible: true, tonguePosition: 0.5
                    },
                    
                    // W - Rounded semi-vowel (w)
                    w: {
                        width: 22, height: 10, curve: 0, asymmetry: 0,
                        lipThickness: 4, cornerHeight: 0, compression: 0.5, stretch: 0,
                        teethVisible: false
                    },
                    
                    // Y - Palatal semi-vowel (y)
                    y: {
                        width: 45, height: 6, curve: 0.4, asymmetry: 0,
                        lipThickness: 1, cornerHeight: 0.2, compression: 0, stretch: -0.1,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.7
                    },
                    
                    // CH - Affricate (ch, j)
                    ch: {
                        width: 38, height: 8, curve: 0, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0, compression: 0.1, stretch: 0,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.6
                    },
                    
                    // R - American R (retroflex)
                    r: {
                        width: 40, height: 10, curve: 0.1, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0.05, compression: 0.1, stretch: 0,
                        teethVisible: true, tongueVisible: true, tonguePosition: 0.4
                    },
                    
                    // SEMI-OPEN - Intermediate between rest and open (for smoother transitions)
                    semiopen: {
                        width: 38, height: 10, curve: 0.1, asymmetry: 0,
                        lipThickness: 2, cornerHeight: 0.05, compression: 0, stretch: 0.1,
                        teethVisible: false, tongueVisible: true, tonguePosition: 0.4
                    }
                };

                // TRANSITION BLENDING SYSTEM for smooth animations
                this.transitionBlends = {
                    // Define which visemes can smoothly blend into each other
                    'rest': ['semiopen', 'closed', 'uh'],
                    'closed': ['rest', 'semiopen', 'oo', 'w'],
                    'open': ['semiopen', 'ay', 'aw', 'ah'],
                    'ee': ['y', 'ay', 'semiopen'],
                    'oh': ['aw', 'oo', 'uh'],
                    'oo': ['w', 'oh', 'closed'],
                    's': ['th', 'ch', 'ee'],
                    'fv': ['closed', 'th'],
                    'th': ['s', 'fv', 't'],
                    'l': ['r', 't', 'semiopen'],
                    'k': ['uh', 'semiopen'],
                    't': ['th', 'l', 'ch'],
                    'ay': ['ee', 'open', 'y'],
                    'aw': ['oh', 'open'],
                    'uh': ['rest', 'semiopen', 'k'],
                    'w': ['oo', 'closed'],
                    'y': ['ee', 'ay'],
                    'ch': ['s', 't'],
                    'r': ['l', 'uh'],
                    'semiopen': ['rest', 'open', 'uh']
                };

                // Animation state tracking for smoother transitions
                this.currentViseme = 'rest';
                this.targetViseme = 'rest';
                this.isTransitioning = false;
                this.transitionProgress = 0;
                
                // Create the parametric mouth shape
                this.createParametricMouth();
                
                // Generate current expressions with variations
                this.generateExpressionVariations();
            }

            generateExpressionVariations() {
                this.expressions = {};
                
                Object.keys(this.baseExpressions).forEach(emotion => {
                    const base = this.baseExpressions[emotion];
                    
                    // Add small random variations while preserving emotion
                    const variation = {
                        head: base.head,
                        leftEye: {
                            cx: base.leftEye.cx + this.randomVariation(2), 
                            cy: base.leftEye.cy + this.randomVariation(1), 
                            r: Math.max(5, base.leftEye.r + this.randomVariation(1))
                        },
                        rightEye: {
                            cx: base.rightEye.cx + this.randomVariation(2), 
                            cy: base.rightEye.cy + this.randomVariation(1), 
                            r: Math.max(5, base.rightEye.r + this.randomVariation(1))
                        },
                        mouth: {
                            cx: base.mouth.cx + this.randomVariation(1), 
                            cy: base.mouth.cy + this.randomVariation(0.5), 
                            rx: Math.max(3, base.mouth.rx + this.randomVariation(0.5)), 
                            ry: Math.max(1, base.mouth.ry + this.randomVariation(0.5))
                        },
                        headRotation: base.headRotation + this.randomVariation(0.5)
                    };
                    
                    this.expressions[emotion] = variation;
                });
            }

            randomVariation(maxRange) {
                return (Math.random() - 0.5) * 2 * maxRange;
            }

            initializeAnimationSystem() {
                this.setInitialPaths();
                this.setupMorphingAnimations();
            }

            setInitialPaths() {
                const idle = this.expressions.idle;
                this.head.setAttribute('d', idle.head);
                this.leftEye.setAttribute('cx', idle.leftEye.cx);
                this.leftEye.setAttribute('cy', idle.leftEye.cy);
                this.leftEye.setAttribute('r', idle.leftEye.r);
                this.rightEye.setAttribute('cx', idle.rightEye.cx);
                this.rightEye.setAttribute('cy', idle.rightEye.cy);
                this.rightEye.setAttribute('r', idle.rightEye.r);
                this.mouth.setAttribute('cx', idle.mouth.cx);
                this.mouth.setAttribute('cy', idle.mouth.cy);
                this.mouth.setAttribute('rx', idle.mouth.rx);
                this.mouth.setAttribute('ry', idle.mouth.ry);
            }

            setupMorphingAnimations() {
                this.morphFunctions = {};
                
                Object.keys(this.expressions).forEach(emotion => {
                    this.morphFunctions[emotion] = {};
                    const paths = this.expressions[emotion];
                    
                    // Only setup morphing for head (path) - eyes and mouth use GSAP attribute animation
                    ['head'].forEach(element => {
                        this.morphFunctions[emotion][element] = {};
                        
                        Object.keys(this.expressions).forEach(targetEmotion => {
                            if (emotion !== targetEmotion) {
                                try {
                                    this.morphFunctions[emotion][element][targetEmotion] = 
                                        flubber.interpolate(paths[element], this.expressions[targetEmotion][element]);
                                } catch (e) {
                                    console.warn(`Failed to create morph from ${emotion} to ${targetEmotion} for ${element}`);
                                }
                            }
                        });
                    });
                });
            }

            setExpression(emotion, immediate = false) {
                if (immediate) {
                    this.setImmediateExpression(emotion);
                } else {
                    this.transitionToExpression(emotion);
                }
            }

            setImmediateExpression(emotion) {
                if (!this.expressions[emotion]) return;
                
                const paths = this.expressions[emotion];
                this.head.setAttribute('d', paths.head);
                this.leftEye.setAttribute('cx', paths.leftEye.cx);
                this.leftEye.setAttribute('cy', paths.leftEye.cy);
                this.leftEye.setAttribute('r', paths.leftEye.r);
                this.rightEye.setAttribute('cx', paths.rightEye.cx);
                this.rightEye.setAttribute('cy', paths.rightEye.cy);
                this.rightEye.setAttribute('r', paths.rightEye.r);
                this.mouth.setAttribute('cx', paths.mouth.cx);
                this.mouth.setAttribute('cy', paths.mouth.cy);
                this.mouth.setAttribute('rx', paths.mouth.rx);
                this.mouth.setAttribute('ry', paths.mouth.ry);
                
                this.currentEmotion = emotion;
            }

            transitionToExpression(emotion) {
                if (emotion === this.currentEmotion || this.isAnimating) return;
                
                this.isAnimating = true;
                const duration = this.options.animationDuration;
                
                // Regenerate expressions with slight variations each time
                this.generateExpressionVariations();
                
                const timeline = gsap.timeline({
                    onComplete: () => {
                        this.currentEmotion = emotion;
                        this.isAnimating = false;
                    }
                });
                
                // Get target expression
                const targetExpression = this.expressions[emotion];
                
                // Animate head rotation
                timeline.to(this.head, {
                    duration: duration / 1000 * 2,
                    rotation: targetExpression.headRotation,
                    ease: "cubic-bezier(0, 0, 0.58, 1)",
                    transformOrigin: "center center"
                }, 0);
                
                // Animate head morphing
                const headMorphFunction = this.morphFunctions[this.currentEmotion]?.head?.[emotion];
                if (headMorphFunction) {
                    const headElement = this.head;
                    timeline.to({}, {
                        duration: duration / 1000 * 2,
                        ease: "cubic-bezier(0, 0, 0.58, 1)",
                        onUpdate: function() {
                            const progress = timeline.progress();
                            const newPath = headMorphFunction(progress);
                            headElement.setAttribute('d', newPath);
                        }
                    }, 0);
                }
                
                // Animate left eye
                timeline.to(this.leftEye, {
                    duration: duration / 1000 * 2,
                    attr: {
                        cx: targetExpression.leftEye.cx,
                        cy: targetExpression.leftEye.cy,
                        r: targetExpression.leftEye.r
                    },
                    ease: "cubic-bezier(0, 0, 0.58, 1)"
                }, 0);
                
                // Animate right eye
                timeline.to(this.rightEye, {
                    duration: duration / 1000 * 2,
                    attr: {
                        cx: targetExpression.rightEye.cx,
                        cy: targetExpression.rightEye.cy,
                        r: targetExpression.rightEye.r
                    },
                    ease: "cubic-bezier(0, 0, 0.58, 1)"
                }, 0);
                
                // Animate mouth
                timeline.to(this.mouth, {
                    duration: duration / 1000 * 2,
                    attr: {
                        cx: targetExpression.mouth.cx,
                        cy: targetExpression.mouth.cy,
                        rx: targetExpression.mouth.rx,
                        ry: targetExpression.mouth.ry
                    },
                    ease: "cubic-bezier(0, 0, 0.58, 1)"
                }, 0);
                
                // Add subtle scaling animation for eyes and mouth
                [this.leftEye, this.rightEye, this.mouth].forEach((element, index) => {
                    timeline.to(element, {
                        duration: duration / 1000,
                        scale: 1.05,
                        ease: "cubic-bezier(0, 0, 0.58, 1)",
                        transformOrigin: "center center"
                    }, index * 0.005);
                    
                    timeline.to(element, {
                        duration: duration / 1000,
                        scale: 1.0,
                        ease: "cubic-bezier(0, 0, 0.58, 1)",
                        transformOrigin: "center center"
                    }, duration / 1000 + index * 0.005);
                });
            }

            analyzeSentiment(text) {
                if (typeof Sentiment !== 'undefined') {
                    const sentiment = new Sentiment();
                    const result = sentiment.analyze(text);
                    const emotion = this.determineEmotion(result);
                    const confidence = Math.abs(result.score) / Math.max(text.split(' ').length, 1);
                    
                    if (confidence > 0.3) {
                        this.setExpression(emotion);
                    }
                    
                    return { emotion, confidence, result };
                }
                return null;
            }

            determineEmotion(sentimentResult) {
                const score = sentimentResult.score;
                const comparative = sentimentResult.comparative;
                const tokens = sentimentResult.tokens.map(t => t.toLowerCase());
                
                // Check for specific emotional keywords first
                if (tokens.some(token => ['amazing', 'incredible', 'fantastic', 'awesome'].includes(token))) {
                    return Math.random() > 0.5 ? 'amazed' : 'ecstatic';
                }
                
                if (tokens.some(token => ['confused', 'puzzled', 'unclear', 'what', 'huh'].includes(token))) {
                    return 'confused';
                }
                
                if (tokens.some(token => ['determined', 'focused', 'will', 'must', 'definitely'].includes(token))) {
                    return 'determined';
                }
                
                if (tokens.some(token => ['worried', 'concerned', 'anxious', 'nervous'].includes(token))) {
                    return 'concerned';
                }
                
                if (tokens.some(token => ['skeptical', 'doubt', 'really', 'sure', 'hmm'].includes(token))) {
                    return 'skeptical';
                }
                
                // Enhanced sentiment-based emotion detection
                if (score > 5) return 'ecstatic';
                if (score > 3) return 'happy';
                if (score > 1) return Math.random() > 0.5 ? 'happy' : 'amazed';
                
                if (score < -5) return Math.random() > 0.5 ? 'sad' : 'concerned';
                if (score < -3) return 'sad';
                if (score < -1) return Math.random() > 0.5 ? 'sad' : 'concerned';
                
                if (Math.abs(comparative) > 0.5) return 'surprised';
                if (Math.abs(comparative) > 0.3) return Math.random() > 0.5 ? 'surprised' : 'amazed';
                
                if (tokens.some(token => 
                    ['think', 'consider', 'maybe', 'perhaps', 'wondering', 'hmm'].includes(token)
                )) {
                    return Math.random() > 0.5 ? 'thinking' : 'confused';
                }
                
                return 'neutral';
            }

            setupPerformanceMonitoring() {
                this.performanceMetrics = {
                    animationFrames: 0,
                    lastFrameTime: performance.now(),
                    avgFrameTime: 16.67
                };
                
                this.startPerformanceMonitoring();
            }

            startPerformanceMonitoring() {
                const monitor = () => {
                    const currentTime = performance.now();
                    const frameTime = currentTime - this.performanceMetrics.lastFrameTime;
                    
                    this.performanceMetrics.avgFrameTime = 
                        (this.performanceMetrics.avgFrameTime * 0.9) + (frameTime * 0.1);
                    
                    this.performanceMetrics.lastFrameTime = currentTime;
                    this.performanceMetrics.animationFrames++;
                    
                    requestAnimationFrame(monitor);
                };
                
                requestAnimationFrame(monitor);
            }

            checkServerStatus() {
                fetch('/api/status')
                    .then(response => response.json())
                    .then(data => {
                        const statusEl = document.getElementById('apiStatus');
                        statusEl.textContent = `‚úÖ Connected to ${data.server_type || 'server'} - Mode: ${data.demo_mode ? 'Demo' : 'Production'}`;
                    })
                    .catch(error => {
                        const statusEl = document.getElementById('apiStatus');
                        statusEl.textContent = '‚ö†Ô∏è Server connection failed';
                    });
            }

            getPerformanceMetrics() {
                return {
                    ...this.performanceMetrics,
                    fps: 1000 / this.performanceMetrics.avgFrameTime,
                    currentEmotion: this.currentEmotion,
                    queueLength: 0,
                    quality: this.options.highQuality ? 'High' : 'Standard'
                };
            }

            // PARAMETRIC MOUTH ANIMATION for real-time lip sync with SMOOTH TRANSITIONS
            updateMouthForPhoneme(phoneme, duration, scaleMultiplier) {
                console.log(`Smooth parametric mouth: ${phoneme}, duration: ${duration}, scale: ${scaleMultiplier}`);
                
                if (!this.phonemeMouths[phoneme]) {
                    console.log(`No mouth parameters found for phoneme: ${phoneme}`);
                    return;
                }

                // Check if we need an intermediate transition for smoothness
                const needsBlending = this.shouldUseBlendedTransition(this.currentViseme, phoneme);
                
                if (needsBlending && !this.isTransitioning) {
                    this.performBlendedTransition(phoneme, duration, scaleMultiplier);
                } else {
                    this.performDirectTransition(phoneme, duration, scaleMultiplier);
                }
            }

            // Check if we should use a blended transition
            shouldUseBlendedTransition(currentViseme, targetViseme) {
                if (currentViseme === targetViseme) return false;
                
                // Check if the visemes are "far apart" and would benefit from intermediate steps
                const currentParams = this.phonemeMouths[currentViseme];
                const targetParams = this.phonemeMouths[targetViseme];
                
                if (!currentParams || !targetParams) return false;
                
                // Calculate "distance" between visemes
                const widthDiff = Math.abs(currentParams.width - targetParams.width);
                const heightDiff = Math.abs(currentParams.height - targetParams.height);
                const curveDiff = Math.abs(currentParams.curve - targetParams.curve);
                
                // If the changes are large, use blended transition
                return (widthDiff > 15 || heightDiff > 10 || curveDiff > 0.4);
            }

            // Perform smooth blended transition through intermediate visemes
            performBlendedTransition(targetPhoneme, duration, scaleMultiplier) {
                this.isTransitioning = true;
                console.log(`Blended transition: ${this.currentViseme} -> ${targetPhoneme}`);
                
                // Find intermediate viseme if available
                const intermediates = this.transitionBlends[this.currentViseme] || [];
                const targetIntermediates = this.transitionBlends[targetPhoneme] || [];
                
                // Find a common intermediate, or use 'semiopen' as fallback
                let intermediate = intermediates.find(v => targetIntermediates.includes(v)) || 'semiopen';
                
                // Special cases for better flow
                if (this.currentViseme === 'rest' && ['open', 'oh', 'aw'].includes(targetPhoneme)) {
                    intermediate = 'semiopen';
                } else if (this.currentViseme === 'closed' && ['ee', 'ay'].includes(targetPhoneme)) {
                    intermediate = 'semiopen';
                }

                const totalDuration = Math.max(duration, 0.4); // Minimum time for smooth blending
                const stepDuration = totalDuration / 2;

                // Step 1: Transition to intermediate
                setTimeout(() => {
                    this.performDirectTransition(intermediate, stepDuration, scaleMultiplier * 0.9);
                }, 0);

                // Step 2: Transition to target
                setTimeout(() => {
                    this.performDirectTransition(targetPhoneme, stepDuration, scaleMultiplier);
                    this.isTransitioning = false;
                }, stepDuration * 1000);
            }

            // Direct transition with improved smoothing
            performDirectTransition(phoneme, duration, scaleMultiplier) {
                // Update current viseme tracking
                this.currentViseme = phoneme;
                
                // Get base parameters for this phoneme
                const baseParams = this.phonemeMouths[phoneme];
                console.log(`Direct transition to ${phoneme}:`, baseParams);
                
                // Apply generative variations for organic feel
                const variationParams = this.generateParametricVariation(phoneme, baseParams, scaleMultiplier);
                
                // Use longer, smoother transition with better easing
                const smoothDuration = Math.max(duration, 0.2); // Minimum duration for visibility
                
                // Smooth transition to new mouth shape using GSAP with improved easing
                this.morphParametricMouth(variationParams, smoothDuration, 'power1.inOut');
                
                // Add secondary facial animations for enhanced realism
                this.addParametricSecondaryAnimations(phoneme, smoothDuration);
            }

            // GENERATIVE PARAMETRIC VARIATION SYSTEM
            generateParametricVariation(phoneme, baseParams, scaleMultiplier) {
                // Start with base parameters
                const variation = { ...baseParams };
                
                // Apply scale multiplier to width and height
                variation.width *= scaleMultiplier;
                variation.height *= scaleMultiplier;
                
                // Add time-based organic variations (breathing, micro-movements)
                const timeOffset = Date.now() / 2000; // Slow organic variation
                const breathingFactor = Math.sin(timeOffset * 3) * 0.05; // 5% breathing variation
                
                // Phoneme-specific organic rules
                switch(phoneme) {
                    case 'open':
                        // Open vowels: Add jaw drop variation
                        variation.height *= (1 + breathingFactor * 2); // More pronounced breathing
                        variation.stretch += Math.sin(timeOffset * 4) * 0.1;
                        break;
                        
                    case 'ee':
                        // Smile shape: Add corner elevation variation
                        variation.cornerHeight += Math.cos(timeOffset * 5) * 0.1;
                        variation.curve += Math.sin(timeOffset * 3) * 0.1;
                        break;
                        
                    case 'oo':
                        // Rounded: Add compression pulsing
                        variation.compression += Math.sin(timeOffset * 6) * 0.1;
                        variation.lipThickness *= (1 + breathingFactor);
                        break;
                        
                    case 's':
                        // Sibilants: Add micro-asymmetry
                        variation.asymmetry += Math.sin(timeOffset * 8) * 0.05;
                        break;
                        
                    case 'fv':
                        // Fricatives: Add lip tension variation
                        variation.lipThickness *= (1 + Math.cos(timeOffset * 7) * 0.2);
                        variation.asymmetry += Math.sin(timeOffset * 4) * 0.1;
                        break;
                        
                    default:
                        // General organic variation
                        variation.width *= (1 + breathingFactor * 0.5);
                        variation.height *= (1 + breathingFactor * 0.3);
                        break;
                }
                
                // Add random micro-variations for ultra-realistic feel (30% chance)
                if (Math.random() > 0.7) {
                    variation.asymmetry += (Math.random() - 0.5) * 0.1;
                    variation.cornerHeight += (Math.random() - 0.5) * 0.05;
                    variation.curve += (Math.random() - 0.5) * 0.1;
                }
                
                console.log(`Generated parametric variation for ${phoneme}:`, variation);
                return variation;
            }

            // SMOOTH PARAMETRIC MORPHING
            morphParametricMouth(targetParams, duration, ease = "power2.inOut") {
                if (!this.mouthGroup) {
                    console.warn('Parametric mouth not initialized');
                    return;
                }
                
                // Create intermediate parameters for smooth interpolation
                const startParams = { ...this.mouthParameters };
                
                // Use GSAP to smoothly interpolate between current and target parameters
                gsap.to(this.mouthParameters, {
                    duration: duration,
                    width: targetParams.width,
                    height: targetParams.height,
                    curve: targetParams.curve,
                    asymmetry: targetParams.asymmetry,
                    lipThickness: targetParams.lipThickness,
                    cornerHeight: targetParams.cornerHeight,
                    compression: targetParams.compression,
                    stretch: targetParams.stretch,
                    ease: ease,
                    onUpdate: () => {
                        // Update the mouth shape every frame during the transition
                        this.updateParametricMouth(this.mouthParameters);
                    },
                    onComplete: () => {
                        // Ensure final state is exact
                        this.updateParametricMouth(targetParams);
                        
                        // Update teeth and tongue visibility
                        if (targetParams.teethVisible !== undefined) {
                            this.mouthParameters.teethVisible = targetParams.teethVisible;
                        }
                        if (targetParams.tongueVisible !== undefined) {
                            this.mouthParameters.tongueVisible = targetParams.tongueVisible;
                            this.mouthParameters.tonguePosition = targetParams.tonguePosition || 0.5;
                        }
                        this.updateParametricMouth(this.mouthParameters);
                    }
                });
                
                console.log(`Started parametric morph from [${startParams.width}x${startParams.height}] to [${targetParams.width}x${targetParams.height}]`);
            }

            // PARAMETRIC SECONDARY ANIMATIONS
            addParametricSecondaryAnimations(phoneme, duration) {
                // Enhanced facial coordination for different phoneme types
                
                // Nostril movement for nasal consonants
                if (['closed', 't', 'k'].includes(phoneme)) {
                    // Subtle nostril flare animation via eye movement
                    gsap.to([this.leftEye, this.rightEye], {
                        duration: duration * 0.3,
                        attr: { cy: `+=${-0.5}` }, // Slight upward movement
                        ease: "power2.out",
                        yoyo: true,
                        repeat: 1
                    });
                }
                
                // Eye dilation for vowel emphasis
                if (['open', 'ee', 'oh', 'oo'].includes(phoneme)) {
                    const currentRadius = parseInt(this.leftEye.getAttribute('r'));
                    gsap.to([this.leftEye, this.rightEye], {
                        duration: duration * 0.2,
                        attr: { r: `+=${1}` }, // Slight dilation
                        ease: "power2.out",
                        yoyo: true,
                        repeat: 1
                    });
                }
                
                // Subtle head movement for emphasis (20/80 rule - body mechanics)
                if (['s', 'fv', 'th'].includes(phoneme)) {
                    gsap.to(this.faceGroup, {
                        duration: 0.15,
                        rotation: Math.random() > 0.5 ? 0.5 : -0.5,
                        ease: "power2.out",
                        yoyo: true,
                        repeat: 1
                    });
                }
            }

            // Add phoneme animation for realistic speaking
            animatePhonemes(text) {
                if (!text) return;
                
                // Simple phoneme mapping based on text
                const phonemes = this.textToPhonemes(text);
                const timeline = gsap.timeline();
                
                phonemes.forEach((phoneme, index) => {
                    const mouthShape = this.phonemeMouths[phoneme] || this.phonemeMouths.medium_open;
                    
                    timeline.to(this.mouth, {
                        duration: 0.15,
                        attr: {
                            cx: mouthShape.cx,
                            cy: mouthShape.cy,
                            rx: mouthShape.rx,
                            ry: mouthShape.ry
                        },
                        ease: "power2.out"
                    }, index * 0.1);
                });
                
                // Return to speaking mouth shape
                timeline.to(this.mouth, {
                    duration: 0.2,
                    attr: {
                        cx: this.expressions.speaking.mouth.cx,
                        cy: this.expressions.speaking.mouth.cy,
                        rx: this.expressions.speaking.mouth.rx,
                        ry: this.expressions.speaking.mouth.ry
                    },
                    ease: "power2.out"
                });
            }
            
            textToPhonemes(text) {
                // Enhanced phoneme mapping with co-articulation consideration
                const phonemeMap = {
                    // Bilabials
                    'b': 'closed', 'm': 'closed', 'p': 'closed',
                    
                    // Fricatives and Sibilants  
                    's': 'small_open', 'z': 'small_open', 'sh': 'small_open', 
                    'ch': 'small_open', 'j': 'small_open',
                    'f': 'teeth_lower', 'v': 'teeth_lower',
                    
                    // Alveolars
                    'd': 'medium_open', 't': 'medium_open', 'n': 'medium_open',
                    
                    // Liquids
                    'l': 'tongue_tip', 'r': 'tongue_tip',
                    
                    // Fricatives
                    'th': 'tongue_tip', // both voiced and unvoiced
                    
                    // Velars
                    'k': 'tongue_back', 'g': 'tongue_back', 'ng': 'tongue_back',
                    
                    // Glottals and Aspirated
                    'h': 'aspirated', 'wh': 'aspirated',
                    
                    // Vowels - High
                    'i': 'tall_narrow', 'ee': 'tall_narrow', 
                    'ih': 'tall_open', 'eh': 'tall_open',
                    
                    // Vowels - Mid
                    'e': 'medium_open', 'uh': 'medium_open',
                    'er': 'medium_open', 'ur': 'medium_open',
                    
                    // Vowels - Low  
                    'a': 'wide_open', 'ah': 'wide_open', 'o': 'wide_open',
                    'aa': 'very_wide', 'aw': 'very_wide',
                    
                    // Rounded vowels
                    'u': 'round_small', 'oo': 'round_medium', 
                    'w': 'round_medium',
                    
                    // Diphthongs
                    'ay': 'diphthong_start', 'oy': 'diphthong_start', 
                    'ow': 'diphthong_start', 'ey': 'diphthong_start'
                };
                
                // Simple word-to-phoneme mapping for common words
                const wordPhonemes = {
                    'the': ['th', 'uh'],
                    'and': ['ah', 'n', 'd'],
                    'hello': ['h', 'eh', 'l', 'ow'],
                    'world': ['w', 'er', 'l', 'd'],
                    'how': ['h', 'ow'],
                    'are': ['ah', 'r'],
                    'you': ['y', 'oo'],
                    'what': ['wh', 'ah', 't'],
                    'when': ['wh', 'eh', 'n'],
                    'where': ['wh', 'eh', 'r'],
                    'this': ['th', 'ih', 's'],
                    'that': ['th', 'ah', 't'],
                    'with': ['w', 'ih', 'th'],
                    'will': ['w', 'ih', 'l'],
                    'can': ['k', 'ah', 'n'],
                    'could': ['k', 'oo', 'd'],
                    'should': ['sh', 'oo', 'd'],
                    'would': ['w', 'oo', 'd']
                };
                
                const phonemes = [];
                const words = text.toLowerCase().split(/\s+/);
                
                for (let word of words) {
                    // Clean word of punctuation
                    const cleanWord = word.replace(/[^\w]/g, '');
                    
                    if (wordPhonemes[cleanWord]) {
                        // Use pre-mapped phonemes for known words
                        phonemes.push(...wordPhonemes[cleanWord]);
                    } else {
                        // Fall back to character-based mapping
                        for (let char of cleanWord) {
                            phonemes.push(phonemeMap[char] || 'medium_open');
                        }
                    }
                    
                    // Add brief pause between words
                    if (words.indexOf(word) < words.length - 1) {
                        phonemes.push('rest');
                    }
                }
                
                return phonemes;
            }

            // PARAMETRIC MOUTH CREATION SYSTEM
            createParametricMouth() {
                // Remove the old ellipse mouth if it exists
                if (this.mouth) {
                    this.mouth.remove();
                }
                
                // Create a group to hold all mouth elements
                this.mouthGroup = document.createElementNS('http://www.w3.org/2000/svg', 'g');
                this.mouthGroup.setAttribute('id', 'parametric-mouth');
                this.mouthGroup.style.transformOrigin = '200px 180px';
                
                // Main mouth shape (vector path)
                this.mouthPath = document.createElementNS('http://www.w3.org/2000/svg', 'path');
                this.mouthPath.setAttribute('fill', '#8B0000'); // Dark red mouth interior
                this.mouthPath.setAttribute('stroke', '#4A0000');
                this.mouthPath.setAttribute('stroke-width', '1');
                this.mouthPath.setAttribute('id', 'mouth-shape');
                
                // Upper lip path
                this.upperLip = document.createElementNS('http://www.w3.org/2000/svg', 'path');
                this.upperLip.setAttribute('fill', '#000000');
                this.upperLip.setAttribute('stroke', 'none');
                this.upperLip.setAttribute('id', 'upper-lip');
                
                // Lower lip path  
                this.lowerLip = document.createElementNS('http://www.w3.org/2000/svg', 'path');
                this.lowerLip.setAttribute('fill', '#000000');
                this.lowerLip.setAttribute('stroke', 'none');
                this.lowerLip.setAttribute('id', 'lower-lip');
                
                // Teeth (optional, for open mouth positions)
                this.teeth = document.createElementNS('http://www.w3.org/2000/svg', 'rect');
                this.teeth.setAttribute('fill', '#FFFFFF');
                this.teeth.setAttribute('stroke', '#E0E0E0');
                this.teeth.setAttribute('stroke-width', '0.5');
                this.teeth.setAttribute('id', 'teeth');
                this.teeth.style.display = 'none'; // Hidden by default
                
                // Tongue (optional, for certain phonemes)
                this.tongue = document.createElementNS('http://www.w3.org/2000/svg', 'ellipse');
                this.tongue.setAttribute('fill', '#FF69B4'); // Pink tongue
                this.tongue.setAttribute('stroke', 'none');
                this.tongue.setAttribute('id', 'tongue');
                this.tongue.style.display = 'none'; // Hidden by default
                
                // Assemble mouth group
                this.mouthGroup.appendChild(this.mouthPath);
                this.mouthGroup.appendChild(this.teeth);
                this.mouthGroup.appendChild(this.tongue);
                this.mouthGroup.appendChild(this.upperLip);
                this.mouthGroup.appendChild(this.lowerLip);
                
                // Add to face
                this.faceGroup.appendChild(this.mouthGroup);
                
                // Set initial mouth shape
                this.updateParametricMouth(this.phonemeMouths.rest);
                
                console.log('Parametric mouth system created');
            }

            // UPDATE PARAMETRIC MOUTH SHAPE
            updateParametricMouth(params) {
                if (!this.mouthGroup) return;
                
                // Merge with current parameters
                const currentParams = { ...this.mouthParameters, ...params };
                
                // Calculate derived values
                const centerX = currentParams.centerX;
                const centerY = currentParams.centerY;
                const width = currentParams.width;
                const height = currentParams.height;
                const curve = currentParams.curve;
                const asymmetry = currentParams.asymmetry;
                const lipThickness = currentParams.lipThickness;
                const cornerHeight = currentParams.cornerHeight;
                const compression = currentParams.compression;
                const stretch = currentParams.stretch;
                
                // Apply compression and stretch
                const effectiveWidth = width * (1 - compression * 0.5);
                const effectiveHeight = height * (1 + stretch * 0.5);
                
                // Calculate corner positions with asymmetry
                const leftCornerX = centerX - effectiveWidth / 2;
                const rightCornerX = centerX + effectiveWidth / 2;
                const leftCornerY = centerY + (cornerHeight * 10) + (asymmetry * 3);
                const rightCornerY = centerY + (cornerHeight * 10) - (asymmetry * 3);
                
                // Calculate control points for curves
                const curveFactor = curve * effectiveWidth * 0.3;
                const upperCurveY = centerY - effectiveHeight / 2 - curveFactor;
                const lowerCurveY = centerY + effectiveHeight / 2 + curveFactor;
                
                // CREATE MAIN MOUTH PATH (interior)
                if (effectiveHeight > 2) {
                    // Open mouth - create interior shape
                    const mouthPath = `
                        M ${leftCornerX} ${leftCornerY}
                        Q ${centerX} ${upperCurveY} ${rightCornerX} ${rightCornerY}
                        Q ${centerX} ${lowerCurveY} ${leftCornerX} ${leftCornerY}
                        Z
                    `;
                    this.mouthPath.setAttribute('d', mouthPath);
                    this.mouthPath.style.display = 'block';
                } else {
                    // Closed mouth - hide interior
                    this.mouthPath.style.display = 'none';
                }
                
                // CREATE LIP PATHS
                const lipHalfThickness = lipThickness / 2;
                
                // Upper lip
                const upperLipPath = `
                    M ${leftCornerX} ${leftCornerY - lipHalfThickness}
                    Q ${centerX} ${upperCurveY - lipHalfThickness} ${rightCornerX} ${rightCornerY - lipHalfThickness}
                    Q ${centerX} ${upperCurveY + lipHalfThickness} ${leftCornerX} ${leftCornerY + lipHalfThickness}
                    Z
                `;
                this.upperLip.setAttribute('d', upperLipPath);
                
                // Lower lip (only if mouth is not too closed)
                if (effectiveHeight > 1) {
                    const lowerLipPath = `
                        M ${leftCornerX} ${leftCornerY + lipHalfThickness}
                        Q ${centerX} ${lowerCurveY - lipHalfThickness} ${rightCornerX} ${rightCornerY + lipHalfThickness}
                        Q ${centerX} ${lowerCurveY + lipHalfThickness} ${leftCornerX} ${leftCornerY + lipHalfThickness}
                        Z
                    `;
                    this.lowerLip.setAttribute('d', lowerLipPath);
                    this.lowerLip.style.display = 'block';
                } else {
                    this.lowerLip.style.display = 'none';
                }
                
                // TEETH VISIBILITY
                if (currentParams.teethVisible && effectiveHeight > 8) {
                    const teethWidth = effectiveWidth * 0.8;
                    const teethHeight = Math.min(effectiveHeight * 0.3, 6);
                    this.teeth.setAttribute('x', centerX - teethWidth / 2);
                    this.teeth.setAttribute('y', centerY - effectiveHeight / 2);
                    this.teeth.setAttribute('width', teethWidth);
                    this.teeth.setAttribute('height', teethHeight);
                    this.teeth.style.display = 'block';
                } else {
                    this.teeth.style.display = 'none';
                }
                
                // TONGUE VISIBILITY
                if (currentParams.tongueVisible && effectiveHeight > 5) {
                    const tongueWidth = effectiveWidth * 0.6;
                    const tongueHeight = Math.min(effectiveHeight * 0.4, 8);
                    const tongueY = centerY + (currentParams.tonguePosition - 0.5) * effectiveHeight;
                    
                    this.tongue.setAttribute('cx', centerX);
                    this.tongue.setAttribute('cy', tongueY);
                    this.tongue.setAttribute('rx', tongueWidth / 2);
                    this.tongue.setAttribute('ry', tongueHeight / 2);
                    this.tongue.style.display = 'block';
                } else {
                    this.tongue.style.display = 'none';
                }
                
                // Store current parameters
                this.mouthParameters = currentParams;
            }
        }

        // Global variables
        let expressionSystem;
        let performanceInterval;
        let audioProcessor; // Audio processing for lip sync input
        let voiceInteractionSystem; // NEW: Complete voice interaction system
        
        // Audio processing class for real-time lip sync (PROFESSIONAL TECHNIQUES)
        class RealTimeAudioProcessor {
            constructor() {
                this.audioContext = null;
                this.analyser = null;
                this.microphone = null;
                this.isListening = false;
                this.dataArray = null;
                this.bufferLength = 0;
                this.lastPhoneme = 'rest';
                this.phonemeHistory = []; // For anticipatory timing
                this.detectedPhonemes = new Set();
                this.frameCounter = 0;
                
                // Professional timing settings
                this.anticipationFrames = 2; // Place shapes 1-2 frames early
                this.holdFrames = 3; // Hold plosives for 3 frames
                
                // Timing control for smoother transitions
                this.lastChangeTime = 0; // Track when we last changed phonemes
                
                // Core 5 shapes for 60-70% coverage (Limited Articulation Principle)
                this.coreShapes = ['rest', 'open', 'closed', 'ee', 'oh'];
                this.coreShapeUsage = 0;
                this.totalShapeUsage = 0;
                
                // SPEECH-TO-TEXT SYSTEM for enhanced phoneme detection
                this.speechRecognition = null;
                this.useSpeechRecognition = false; // Toggle between frequency analysis and speech recognition
                this.speechBuffer = '';
                this.speechPhonemeQueue = [];
                this.lastSpeechUpdate = 0;
                
                this.initializeSpeechRecognition();
            }
            
            // SPEECH-TO-TEXT ENHANCED PHONEME DETECTION
            initializeSpeechRecognition() {
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    this.speechRecognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                    this.speechRecognition.continuous = true;
                    this.speechRecognition.interimResults = true;
                    this.speechRecognition.lang = 'en-US';
                    
                    this.speechRecognition.onresult = (event) => {
                        this.processSpeechResult(event);
                    };
                    
                    this.speechRecognition.onerror = (event) => {
                        console.warn('Speech recognition error:', event.error);
                        // Fall back to frequency analysis
                        this.useSpeechRecognition = false;
                    };
                    
                    console.log('Speech recognition initialized');
                } else {
                    console.log('Speech recognition not supported, using frequency analysis only');
                }
            }
            
            processSpeechResult(event) {
                let finalTranscript = '';
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Use interim results for real-time lip sync
                const currentText = interimTranscript || finalTranscript;
                if (currentText && currentText !== this.speechBuffer) {
                    this.speechBuffer = currentText;
                    
                    // Convert text to phoneme sequence
                    const phonemes = this.textToPhonemeSequence(currentText);
                    this.speechPhonemeQueue = phonemes;
                    this.lastSpeechUpdate = Date.now();
                    
                    console.log(`Speech detected: "${currentText}" -> [${phonemes.join(', ')}]`);
                }
            }
            
            textToPhonemeSequence(text) {
                // Basic phoneme mapping for lip sync
                const words = text.toLowerCase().replace(/[^\w\s]/g, '').split(/\s+/);
                const phonemes = [];
                
                const wordPhonemes = {
                    'hello': ['k', 'open', 'l', 'oh'],
                    'world': ['oo', 'l', 't'],
                    'how': ['k', 'open', 'oo'],
                    'are': ['open', 'l'],
                    'you': ['oo'],
                };
                
                for (let word of words) {
                    if (wordPhonemes[word]) {
                        phonemes.push(...wordPhonemes[word]);
                    } else {
                        // Simple fallback
                        for (let char of word) {
                            if ('aeiou'.includes(char)) {
                                phonemes.push('open');
                            } else {
                                phonemes.push('closed');
                            }
                        }
                    }
                    phonemes.push('rest');
                }
                
                return phonemes;
            }
            
            async startListening() {
                try {
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    
                    // Request microphone access
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: { 
                            echoCancellation: true,
                            noiseSuppression: true,
                            sampleRate: 16000
                        } 
                    });
                    
                    this.microphone = this.audioContext.createMediaStreamSource(stream);
                    this.analyser = this.audioContext.createAnalyser();
                    
                    this.analyser.fftSize = 512;
                    this.analyser.smoothingTimeConstant = 0.8;
                    
                    this.bufferLength = this.analyser.frequencyBinCount;
                    this.dataArray = new Uint8Array(this.bufferLength);
                    
                    this.microphone.connect(this.analyser);
                    this.isListening = true;
                    
                    // Start speech recognition if available
                    if (this.speechRecognition && this.useSpeechRecognition) {
                        try {
                            this.speechRecognition.start();
                            console.log('Speech recognition started for enhanced phoneme detection');
                        } catch (error) {
                            console.warn('Could not start speech recognition:', error);
                            this.useSpeechRecognition = false;
                        }
                    }
                    
                    this.processAudio();
                    console.log('Real-time audio processing started');
                    
                } catch (error) {
                    console.error('Error starting audio:', error);
                }
            }
            
            processAudio() {
                if (!this.isListening) return;
                
                this.analyser.getByteFrequencyData(this.dataArray);
                this.frameCounter++;
                
                // Simple phoneme detection
                const detectedPhoneme = this.detectBasicPhoneme(this.dataArray);
                
                // Apply timing and smoothing
                const currentTime = Date.now();
                const timeSinceLastChange = currentTime - (this.lastChangeTime || 0);
                const minimumHoldTime = 100;
                
                if (detectedPhoneme !== this.lastPhoneme && timeSinceLastChange > minimumHoldTime) {
                    if (expressionSystem && expressionSystem.updateMouthForPhoneme) {
                        expressionSystem.updateMouthForPhoneme(detectedPhoneme, 0.3, 1.0);
                    }
                    
                    this.lastPhoneme = detectedPhoneme;
                    this.lastChangeTime = currentTime;
                }
                
                requestAnimationFrame(() => this.processAudio());
            }
            
            detectBasicPhoneme(frequencyData) {
                // Basic frequency analysis for phoneme detection
                let totalEnergy = 0;
                let highEnergy = 0;
                let midEnergy = 0;
                let lowEnergy = 0;
                
                for (let i = 0; i < frequencyData.length; i++) {
                    const amplitude = frequencyData[i] / 255.0;
                    totalEnergy += amplitude;
                    
                    if (i > frequencyData.length * 0.7) {
                        highEnergy += amplitude;
                    } else if (i > frequencyData.length * 0.3) {
                        midEnergy += amplitude;
                    } else {
                        lowEnergy += amplitude;
                    }
                }
                
                totalEnergy /= frequencyData.length;
                
                if (totalEnergy < 0.05) {
                    return 'rest';
                }
                
                if (highEnergy > midEnergy) {
                    return 's'; // High frequency sounds
                } else if (midEnergy > lowEnergy) {
                    return Math.random() > 0.5 ? 'ee' : 'open'; // Mid frequency vowels
                } else {
                    return Math.random() > 0.5 ? 'oh' : 'closed'; // Low frequency sounds
                }
            }
            
            stopListening() {
                this.isListening = false;
                if (this.microphone) {
                    this.microphone.disconnect();
                }
                if (this.audioContext) {
                    this.audioContext.close();
                }
                
                if (this.speechRecognition && this.useSpeechRecognition) {
                    try {
                        this.speechRecognition.stop();
                    } catch (error) {
                        console.warn('Error stopping speech recognition:', error);
                    }
                }
                audioStatus.style.display = 'none';
            }
        }

        // VISEME TESTING FUNCTIONS
        function testViseme(phoneme) {
            if (expressionSystem && expressionSystem.updateMouthForPhoneme) {
                console.log(`Testing viseme: ${phoneme}`);
                expressionSystem.updateMouthForPhoneme(phoneme, 0.8, 1.2); // Longer duration for testing
                
                // Update UI feedback
                const buttons = document.querySelectorAll('[onclick*="testViseme"]');
                buttons.forEach(btn => btn.style.transform = 'scale(1)');
                event.target.style.transform = 'scale(0.95)';
                setTimeout(() => event.target.style.transform = 'scale(1)', 200);
            } else {
                console.warn('Expression system not ready for viseme testing');
            }
        }

        function testSmoothSequence() {
            if (!expressionSystem) {
                console.warn('Expression system not ready');
                return;
            }
            
            console.log('Starting smooth viseme sequence test...');
            
            // Test sequence that should show smooth blended transitions
            const sequence = [
                { viseme: 'rest', delay: 0 },
                { viseme: 'open', delay: 800 },    // Should blend through semiopen
                { viseme: 'ee', delay: 1600 },     // Should blend through ay
                { viseme: 'oo', delay: 2400 },     // Should blend through oh
                { viseme: 'closed', delay: 3200 }, // Should blend through w
                { viseme: 's', delay: 4000 },      // Should blend through th
                { viseme: 'rest', delay: 4800 }    // Should blend through semiopen
            ];
            
            sequence.forEach(step => {
                setTimeout(() => {
                    console.log(`Sequence step: ${step.viseme}`);
                    expressionSystem.updateMouthForPhoneme(step.viseme, 0.6, 1.1);
                }, step.delay);
            });
            
            // Visual feedback
            const button = event.target;
            button.textContent = 'üåä Testing...';
            button.disabled = true;
            setTimeout(() => {
                button.textContent = 'üåä Test Smooth Sequence';
                button.disabled = false;
            }, 5500);
        }

        function testWordExample() {
            if (!expressionSystem) {
                console.warn('Expression system not ready');
                return;
            }
            
            console.log('Testing "Hello World" with smooth transitions...');
            
            // "Hello World" phoneme sequence with realistic timing
            const helloWorldSequence = [
                { viseme: 'rest', delay: 0 },
                { viseme: 'k', delay: 200 },     // H sound (velar fricative)
                { viseme: 'uh', delay: 400 },    // E sound 
                { viseme: 'l', delay: 600 },     // L sound
                { viseme: 'oh', delay: 800 },    // O sound
                { viseme: 'semiopen', delay: 1000 }, // Brief pause
                { viseme: 'w', delay: 1200 },    // W sound
                { viseme: 'aw', delay: 1400 },   // OR sound
                { viseme: 'l', delay: 1600 },    // L sound
                { viseme: 't', delay: 1800 },    // D sound
                { viseme: 'rest', delay: 2000 }  // End
            ];
            
            helloWorldSequence.forEach(step => {
                setTimeout(() => {
                    console.log(`Word step: ${step.viseme} (${step.delay}ms)`);
                    expressionSystem.updateMouthForPhoneme(step.viseme, 0.4, 1.0);
                }, step.delay);
            });
            
            // Visual feedback
            const button = event.target;
            button.textContent = 'üìù Speaking...';
            button.disabled = true;
            setTimeout(() => {
                button.textContent = 'üìù Test "Hello World"';
                button.disabled = false;
            }, 2500);
        }
        
        // VOICE INTERACTION CONTROL FUNCTIONS
        function startVoiceInteraction() {
            if (!voiceInteractionSystem) {
                alert('Voice interaction system not ready. Please refresh the page.');
                return;
            }
            
            // Start the voice interaction system
            voiceInteractionSystem.start();
            
            // Show status
            console.log('Voice interaction started from UI');
            
            // Visual feedback
            const button = event.target;
            button.textContent = 'üéôÔ∏è Voice Chat Active';
            button.style.background = '#2ecc71';
        }
        
        function stopVoiceInteraction() {
            if (!voiceInteractionSystem) {
                console.warn('Voice interaction system not available');
                return;
            }
            
            // Stop the voice interaction system
            voiceInteractionSystem.stop();
            
            // Reset button
            const startButton = document.querySelector('[onclick="startVoiceInteraction()"]');
            if (startButton) {
                startButton.textContent = 'üéôÔ∏è Start Voice Chat';
                startButton.style.background = '#27ae60';
            }
            
            console.log('Voice interaction stopped from UI');
        }
        
        function testTTSWithAnimation() {
            if (!voiceInteractionSystem) {
                alert('Voice interaction system not ready. Please refresh the page.');
                return;
            }
            
            // Run the TTS animation test
            voiceInteractionSystem.testTTSWithAnimation();
            
            // Visual feedback
            const button = event.target;
            const originalText = button.textContent;
            button.textContent = 'üß™ Testing...';
            button.disabled = true;
            
            setTimeout(() => {
                button.textContent = originalText;
                button.disabled = false;
            }, 8000); // Test takes about 8 seconds
        }
        
        // COMPREHENSIVE VOICE INTERACTION SYSTEM
        class VoiceInteractionSystem {
            constructor() {
                this.isActive = false;
                this.isListening = false;
                this.isSpeaking = false;
                
                // Voice input components
                this.speechRecognition = null;
                this.speechBuffer = '';
                this.lastSpeechTime = 0;
                
                // TTS components
                this.speechSynthesis = window.speechSynthesis;
                this.currentVoice = null;
                this.speechQueue = [];
                
                // Animation sync
                this.currentTTSText = '';
                this.ttsStartTime = 0;
                this.ttsAnimationInterval = null;
                
                // Configuration
                this.config = {
                    voiceInput: false,
                    aiResponse: false,
                    ttsOutput: false,
                    autoExpressions: true
                };
                
                this.initialize();
            }
            
            initialize() {
                this.setupSpeechRecognition();
                this.setupTTS();
                this.loadVoices();
                console.log('Voice Interaction System initialized');
            }
            
            setupSpeechRecognition() {
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    this.speechRecognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                    this.speechRecognition.continuous = true;
                    this.speechRecognition.interimResults = false;
                    this.speechRecognition.lang = 'en-US';
                    
                    this.speechRecognition.onstart = () => {
                        this.isListening = true;
                        this.updateStatus('üé§ Listening for your voice...');
                        if (expressionSystem) expressionSystem.setExpression('awake');
                    };
                    
                    this.speechRecognition.onresult = (event) => {
                        this.processSpeechInput(event);
                    };
                    
                    this.speechRecognition.onerror = (event) => {
                        console.warn('Speech recognition error:', event.error);
                        this.updateStatus(`‚ùå Speech error: ${event.error}`);
                    };
                    
                    this.speechRecognition.onend = () => {
                        this.isListening = false;
                        if (this.isActive && this.config.voiceInput) {
                            setTimeout(() => {
                                if (this.isActive && !this.isSpeaking) {
                                    this.speechRecognition.start();
                                }
                            }, 500);
                        }
                    };
                } else {
                    console.warn('Speech recognition not supported');
                }
            }
            
            setupTTS() {
                if (this.speechSynthesis) {
                    this.speechSynthesis.onvoiceschanged = () => this.loadVoices();
                }
            }
            
            loadVoices() {
                const voices = this.speechSynthesis.getVoices();
                const preferredVoices = ['Samantha', 'Alex', 'Google UK English Female'];
                
                for (const preferred of preferredVoices) {
                    const voice = voices.find(v => v.name.includes(preferred));
                    if (voice) {
                        this.currentVoice = voice;
                        break;
                    }
                }
                
                if (!this.currentVoice && voices.length > 0) {
                    this.currentVoice = voices[0];
                }
            }
            
            processSpeechInput(event) {
                let finalTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    if (event.results[i].isFinal) {
                        finalTranscript += event.results[i][0].transcript;
                    }
                }
                
                if (finalTranscript.trim()) {
                    this.speechBuffer = finalTranscript.trim();
                    console.log(`Speech input: "${this.speechBuffer}"`);
                    this.updateStatus(`üí≠ You said: "${this.speechBuffer}"`);
                    this.processUserInput(this.speechBuffer);
                }
            }
            
            async processUserInput(userText) {
                if (!userText.trim()) return;
                
                if (expressionSystem && this.config.autoExpressions) {
                    expressionSystem.setExpression('thinking');
                }
                
                this.updateStatus('üß† Processing your request...');
                
                try {
                    let response;
                    if (this.config.aiResponse) {
                        response = await this.getAIResponse(userText);
                    } else {
                        response = this.getLocalResponse(userText);
                    }
                    
                    if (response) {
                        if (this.config.autoExpressions) {
                            this.setExpressionFromText(response);
                        }
                        
                        if (this.config.ttsOutput) {
                            await this.speakWithAnimation(response);
                        } else {
                            this.updateStatus(`üí¨ Response: "${response}"`);
                        }
                    }
                } catch (error) {
                    console.error('Error processing input:', error);
                    this.updateStatus(`‚ùå Error: ${error.message}`);
                    if (expressionSystem) expressionSystem.setExpression('confused');
                }
            }
            
            async getAIResponse(userText) {
                try {
                    const response = await fetch('/api/command/' + encodeURIComponent(userText));
                    const data = await response.json();
                    
                    if (data.success && data.response) {
                        return data.response;
                    } else {
                        throw new Error(data.error || 'No response from AI');
                    }
                } catch (error) {
                    return this.getLocalResponse(userText);
                }
            }
            
            getLocalResponse(userText) {
                const text = userText.toLowerCase();
                
                if (text.includes('hello') || text.includes('hi')) {
                    return "Hello! It's wonderful to see you. How can I help you today?";
                }
                if (text.includes('how are you')) {
                    return "I'm doing great, thank you for asking! I'm excited to chat with you.";
                }
                if (text.includes('time')) {
                    return `The current time is ${new Date().toLocaleTimeString()}.`;
                }
                if (text.includes('thank')) {
                    return "You're very welcome! I'm always happy to help.";
                }
                if (text.includes('bye')) {
                    return "Goodbye! It was lovely talking with you. Take care!";
                }
                
                return `That's interesting. You said: "${userText}". I'm thinking about how to help you.`;
            }
            
            setExpressionFromText(text) {
                if (!expressionSystem) return;
                
                const sentimentResult = expressionSystem.analyzeSentiment(text);
                if (sentimentResult && sentimentResult.emotion) {
                    expressionSystem.setExpression(sentimentResult.emotion);
                } else {
                    const textLower = text.toLowerCase();
                    if (textLower.includes('wonderful') || textLower.includes('great')) {
                        expressionSystem.setExpression('happy');
                    } else if (textLower.includes('sorry')) {
                        expressionSystem.setExpression('concerned');
                    } else {
                        expressionSystem.setExpression('speaking');
                    }
                }
            }
            
            async speakWithAnimation(text) {
                return new Promise((resolve) => {
                    const utterance = new SpeechSynthesisUtterance(text);
                    utterance.voice = this.currentVoice;
                    utterance.rate = 0.9;
                    utterance.volume = 0.8;
                    
                    this.isSpeaking = true;
                    
                    // Start lip sync animation
                    if (expressionSystem) {
                        this.startTTSAnimation(text);
                    }
                    
                    utterance.onstart = () => {
                        this.updateStatus(`üó£Ô∏è Speaking: "${text}"`);
                    };
                    
                    utterance.onend = () => {
                        this.isSpeaking = false;
                        this.stopTTSAnimation();
                        if (expressionSystem) expressionSystem.setExpression('idle');
                        this.updateStatus('‚úÖ Ready for next input');
                        resolve();
                    };
                    
                    utterance.onerror = (error) => {
                        this.isSpeaking = false;
                        this.stopTTSAnimation();
                        this.updateStatus(`‚ùå TTS error: ${error.error}`);
                        resolve();
                    };
                    
                    this.speechSynthesis.speak(utterance);
                });
            }
            
            startTTSAnimation(text) {
                if (!expressionSystem || !expressionSystem.updateMouthForPhoneme) return;
                
                const phonemes = this.textToPhonemeSequence(text);
                let phonemeIndex = 0;
                const avgPhonemeTime = 150;
                
                this.ttsAnimationInterval = setInterval(() => {
                    if (phonemeIndex < phonemes.length && this.isSpeaking) {
                        const phoneme = phonemes[phonemeIndex];
                        expressionSystem.updateMouthForPhoneme(phoneme, 0.3, 1.0);
                        phonemeIndex++;
                    } else {
                        this.stopTTSAnimation();
                    }
                }, avgPhonemeTime);
            }
            
            stopTTSAnimation() {
                if (this.ttsAnimationInterval) {
                    clearInterval(this.ttsAnimationInterval);
                    this.ttsAnimationInterval = null;
                }
                if (expressionSystem && expressionSystem.updateMouthForPhoneme) {
                    expressionSystem.updateMouthForPhoneme('rest', 0.3, 1.0);
                }
            }
            
            textToPhonemeSequence(text) {
                const words = text.toLowerCase().replace(/[^\w\s]/g, '').split(/\s+/);
                const phonemes = [];
                
                const wordPhonemes = {
                    'hello': ['k', 'uh', 'l', 'oh'],
                    'hi': ['k', 'open'],
                    'wonderful': ['w', 'uh', 't', 'fv', 'oo', 'l'],
                    'thank': ['th', 'ay', 'k'],
                    'you': ['oo'],
                    'great': ['k', 'ay', 't']
                };
                
                for (const word of words) {
                    if (wordPhonemes[word]) {
                        phonemes.push(...wordPhonemes[word]);
                    } else {
                        // Simple fallback
                        for (const char of word) {
                            if ('aeiou'.includes(char)) {
                                phonemes.push(char === 'a' ? 'open' : 'oh');
                            } else {
                                phonemes.push('closed');
                            }
                        }
                    }
                    phonemes.push('rest');
                }
                
                return phonemes;
            }
            
            updateStatus(message) {
                const statusElement = document.getElementById('voiceInteractionStatus');
                if (statusElement) {
                    statusElement.textContent = message;
                }
                console.log(`Voice Interaction: ${message}`);
            }
            
            start() {
                this.isActive = true;
                this.updateStatus('üöÄ Voice interaction started');
                
                if (this.config.voiceInput && this.speechRecognition) {
                    try {
                        this.speechRecognition.start();
                    } catch (error) {
                        this.updateStatus('‚ùå Could not start speech recognition');
                    }
                }
            }
            
            stop() {
                this.isActive = false;
                this.isListening = false;
                
                if (this.speechRecognition) {
                    try {
                        this.speechRecognition.stop();
                    } catch (error) {
                        console.warn('Error stopping speech:', error);
                    }
                }
                
                if (this.speechSynthesis) {
                    this.speechSynthesis.cancel();
                }
                
                this.isSpeaking = false;
                this.stopTTSAnimation();
                
                if (expressionSystem) expressionSystem.setExpression('idle');
                this.updateStatus('‚èπÔ∏è Voice interaction stopped');
            }
            
            updateConfig(newConfig) {
                this.config = { ...this.config, ...newConfig };
                console.log('Config updated:', this.config);
            }
            
            async testTTSWithAnimation() {
                const testTexts = [
                    "Hello! This is a test of text-to-speech with facial animation.",
                    "Watch my mouth move as I speak different words and sounds."
                ];
                
                for (const text of testTexts) {
                    this.setExpressionFromText(text);
                    await this.speakWithAnimation(text);
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
                this.updateStatus('‚úÖ TTS test completed');
            }
        }
        
        // Initialize the expression system
        document.addEventListener('DOMContentLoaded', function() {
            console.log('=== Initializing Expression System ===');
            
            expressionSystem = new HighQualityExpressionSystem('avatarContainer', {
                enableSentimentAnalysis: true,
                animationDuration: 200,
                highQuality: true
            });
            
            console.log('Expression system created:', !!expressionSystem);
            console.log('Phoneme mouths:', Object.keys(expressionSystem.phonemeMouths || {}));
            
            // Initialize audio processor
            audioProcessor = new RealTimeAudioProcessor();
            
            console.log('Audio processor created:', !!audioProcessor);
            
            // Initialize voice interaction system
            voiceInteractionSystem = new VoiceInteractionSystem();
            
            console.log('Voice interaction system created:', !!voiceInteractionSystem);
            
            setupEventListeners();
            
            // Set to idle state instead of cycling demo
            setTimeout(() => {
                console.log('Setting initial idle expression');
                expressionSystem.setExpression('idle');
            }, 500);
            
            console.log('=== Initialization Complete ===');
        });
        
        function setupEventListeners() {
            document.getElementById('sentimentToggle').addEventListener('change', function() {
                expressionSystem.options.enableSentimentAnalysis = this.checked;
            });
            
            document.getElementById('performanceToggle').addEventListener('change', function() {
                const metricsDiv = document.getElementById('performanceMetrics');
                if (this.checked) {
                    metricsDiv.style.display = 'block';
                    startPerformanceMonitoring();
                } else {
                    metricsDiv.style.display = 'none';
                    if (performanceInterval) {
                        clearInterval(performanceInterval);
                    }
                }
            });

            document.getElementById('qualityToggle').addEventListener('change', function() {
                expressionSystem.options.highQuality = this.checked;
                // Could implement dynamic quality switching here
            });
            
            // Real-time audio lip sync toggle
            document.getElementById('audioLipSyncToggle').addEventListener('change', async function() {
                const audioStatus = document.getElementById('audioStatus');
                
                if (this.checked) {
                    try {
                        await audioProcessor.startListening();
                        console.log('Real-time lip sync enabled');
                        // Set to speaking mode when audio is active
                        expressionSystem.setExpression('speaking');
                        // Show audio status
                        audioStatus.style.display = 'block';
                    } catch (error) {
                        console.error('Failed to start audio:', error);
                        this.checked = false;
                        alert('Microphone access denied or not available');
                        audioStatus.style.display = 'none';
                    }
                } else {
                    audioProcessor.stopListening();
                    console.log('Real-time lip sync disabled');
                    // Return to neutral when audio stops
                    expressionSystem.setExpression('neutral');
                    // Hide audio status
                    audioStatus.style.display = 'none';
                }
            });
            
            // Speech recognition mode toggle
            document.getElementById('speechRecognitionToggle').addEventListener('change', function() {
                if (audioProcessor) {
                    audioProcessor.useSpeechRecognition = this.checked;
                    
                    if (this.checked) {
                        // Start speech recognition if audio is already listening
                        if (audioProcessor.isListening && audioProcessor.speechRecognition) {
                            try {
                                audioProcessor.speechRecognition.start();
                                console.log('Speech recognition mode enabled');
                            } catch (error) {
                                console.warn('Could not start speech recognition:', error);
                                this.checked = false;
                                audioProcessor.useSpeechRecognition = false;
                                alert('Speech recognition not available. Using frequency analysis.');
                            }
                        }
                    } else {
                        // Stop speech recognition
                        if (audioProcessor.speechRecognition) {
                            try {
                                audioProcessor.speechRecognition.stop();
                                console.log('Speech recognition mode disabled - using frequency analysis');
                            } catch (error) {
                                console.warn('Error stopping speech recognition:', error);
                            }
                        }
                    }
                    
                    console.log(`Phoneme detection mode: ${this.checked ? 'Speech-to-Text' : 'Frequency Analysis'}`);
                }
            });
            
            // Voice Interaction System Event Listeners
            document.getElementById('voiceInputToggle').addEventListener('change', function() {
                if (voiceInteractionSystem) {
                    voiceInteractionSystem.updateConfig({ voiceInput: this.checked });
                    console.log('Voice input toggled:', this.checked);
                }
            });
            
            document.getElementById('aiResponseToggle').addEventListener('change', function() {
                if (voiceInteractionSystem) {
                    voiceInteractionSystem.updateConfig({ aiResponse: this.checked });
                    console.log('AI response toggled:', this.checked);
                }
            });
            
            document.getElementById('ttsOutputToggle').addEventListener('change', function() {
                if (voiceInteractionSystem) {
                    voiceInteractionSystem.updateConfig({ ttsOutput: this.checked });
                    console.log('TTS output toggled:', this.checked);
                }
            });
            
            document.getElementById('autoExpressionsToggle').addEventListener('change', function() {
                if (voiceInteractionSystem) {
                    voiceInteractionSystem.updateConfig({ autoExpressions: this.checked });
                    console.log('Auto expressions toggled:', this.checked);
                }
            });
            
            document.getElementById('textInput').addEventListener('keypress', function(e) {
                if (e.key === 'Enter') {
                    analyzeText();
                }
            });
        }

        function setEmotion(emotion) {
            // Update active button
            document.querySelectorAll('.emotion-btn').forEach(btn => btn.classList.remove('active'));
            event.target.classList.add('active');
            
            // Set expression
            expressionSystem.setExpression(emotion);
        }
        
        function analyzeText() {
            const text = document.getElementById('textInput').value.trim();
            if (text) {
                const result = expressionSystem.analyzeSentiment(text);
                console.log('Sentiment analysis:', result);
                
                // Trigger phoneme animation if speaking-related
                if (result && (result.emotion === 'speaking' || text.length > 20)) {
                    setTimeout(() => {
                        expressionSystem.animatePhonemes(text);
                    }, 300);
                }
                
                document.getElementById('textInput').value = '';
            }
        }

        function fetchServerSentiment() {
            const text = document.getElementById('textInput').value.trim();
            if (!text) return;

            fetch('/api/analyze_sentiment', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ text: text })
            })
            .then(response => response.json())
            .then(data => {
                console.log('Server sentiment analysis:', data);
                if (data.emotion && data.confidence > 0.3) {
                    expressionSystem.setExpression(data.emotion);
                    
                    // Trigger phoneme animation if speaking-related
                    if (data.emotion === 'speaking' || text.length > 20) {
                        setTimeout(() => {
                            expressionSystem.animatePhonemes(text);
                        }, 300);
                    }
                }
                document.getElementById('textInput').value = '';
            })
            .catch(error => {
                console.error('Error:', error);
                // Fall back to client-side analysis
                analyzeText();
            });
        }
        
        function analyzePresetText(text) {
            document.getElementById('textInput').value = text;
            const result = expressionSystem.analyzeSentiment(text);
            console.log('Preset sentiment analysis:', result);
            
            setTimeout(() => {
                document.getElementById('textInput').value = '';
            }, 1000);
        }
        
        function startPerformanceMonitoring() {
            if (performanceInterval) clearInterval(performanceInterval);
            
            performanceInterval = setInterval(() => {
                const metrics = expressionSystem.getPerformanceMetrics();
                
                document.getElementById('fpsMetric').textContent = Math.round(metrics.fps);
                document.getElementById('emotionMetric').textContent = metrics.currentEmotion;
                document.getElementById('queueMetric').textContent = metrics.queueLength;
                document.getElementById('framesMetric').textContent = metrics.animationFrames;
                if (document.getElementById('qualityMetric')) {
                    document.getElementById('qualityMetric').textContent = metrics.quality;
                }
            }, 500);
        }

        function toggleAudioDebug() {
            const audioStatus = document.getElementById('audioStatus');
            if (audioStatus.style.display === 'none') {
                audioStatus.style.display = 'block';
            } else {
                audioStatus.style.display = 'none';
            }
        }

        function testSVGMouth() {
            console.log('=== Testing Parametric Mouth System ===');
            console.log('Expression system exists:', !!expressionSystem);
            
            if (expressionSystem) {
                console.log('Phoneme parameters available:', Object.keys(expressionSystem.phonemeMouths || {}));
                
                // Test all parametric mouth shapes in sequence
                const parametricPhonemes = ['rest', 'closed', 'open', 'ee', 'oh', 'oo', 's', 'fv', 'th', 'l', 'k', 't'];
                let index = 0;
                
                function cycleNextMouth() {
                    if (index < parametricPhonemes.length) {
                        const phoneme = parametricPhonemes[index];
                        console.log(`=== Testing Parametric mouth ${index + 1}/${parametricPhonemes.length}: ${phoneme} ===`);
                        expressionSystem.updateMouthForPhoneme(phoneme, 0.3, 1.2);
                        index++;
                        setTimeout(cycleNextMouth, 1000); // Wait 1 second between each
                    } else {
                        console.log('=== Parametric mouth test complete ===');
                        // Return to neutral
                        expressionSystem.setExpression('idle');
                    }
                }
                
                cycleNextMouth();
            } else {
                console.error('Expression system not found');
            }
        }
    </script>
</body>
</html> 